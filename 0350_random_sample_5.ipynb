{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import sqlite3\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Sample 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_fifth_random_sample():\n",
    "    source_db = \"sampling_frame.db\"\n",
    "    sample1_db = \"random_sample_1.db\"\n",
    "    sample2_db = \"random_sample_2.db\"\n",
    "    sample3_db = \"random_sample_3.db\"\n",
    "    sample4_db = \"random_sample_4.db\"\n",
    "    fifth_sample_db = \"random_sample_5.db\"\n",
    "    table_name = \"sampled_collections\"\n",
    "    sample_size = 40\n",
    "\n",
    "    # Load full dataset\n",
    "    conn_source = sqlite3.connect(source_db)\n",
    "    df_full = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn_source)\n",
    "    conn_source.close()\n",
    "\n",
    "    # Load previous samples\n",
    "    conn1 = sqlite3.connect(sample1_db)\n",
    "    df1 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn1)\n",
    "    conn1.close()\n",
    "\n",
    "    conn2 = sqlite3.connect(sample2_db)\n",
    "    df2 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn2)\n",
    "    conn2.close()\n",
    "\n",
    "    conn3 = sqlite3.connect(sample3_db)\n",
    "    df3 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn3)\n",
    "    conn3.close()\n",
    "\n",
    "    conn4 = sqlite3.connect(sample4_db)\n",
    "    df4 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn4)\n",
    "    conn4.close()    \n",
    "\n",
    "    # Check for required column\n",
    "    if \"slug_name\" not in df_full.columns:\n",
    "        raise ValueError(\"Missing 'slug_name' column in source data.\")\n",
    "\n",
    "    # Exclude all previously sampled collection_ids\n",
    "    previously_sampled_ids = set(df1[\"slug_name\"]).union(df2[\"slug_name\"], df3[\"slug_name\"], df4[\"slug_name\"])\n",
    "    df_remaining = df_full[~df_full[\"slug_name\"].isin(previously_sampled_ids)]\n",
    "\n",
    "    print(f\"Remaining collections after excluding first 4 samples: {len(df_remaining)}\")\n",
    "\n",
    "    # Draw the fourth sample\n",
    "    df_fifth_sample = df_remaining.sample(n=sample_size, random_state=789)\n",
    "    print(f\"Sampled {len(df_fifth_sample)} collections for fifth sample.\")\n",
    "\n",
    "    # Write to new database\n",
    "    conn_fifth = sqlite3.connect(fifth_sample_db)\n",
    "    df_fifth_sample.to_sql(table_name, conn_fifth, if_exists=\"replace\", index=False)\n",
    "    conn_fifth.close()\n",
    "\n",
    "    print(f\"Fifth sample saved to '{df_fifth_sample}' in table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining collections after excluding first 4 samples: 87\n",
      "Sampled 40 collections for fifth sample.\n",
      "Fifth sample saved to '          id                                      collection_id marketplace  \\\n",
      "31    448440   0x716ad1b6222046289c1664825cd9e4caf6253aec:match     Rarible   \n",
      "39   5195586   0xdc9c44cefa0a48bd94f10a922a7b54af8a989e95:blast     OpenSea   \n",
      "62   5423467                                               None   MagicEden   \n",
      "77   4669448    0xb87d431ce921c33b7fd69bf7aa665caac63d6d31:zora     OpenSea   \n",
      "17   4329255  0xa534852c55647201ae5413dfd398b5b35a1b6dc4:ape...     OpenSea   \n",
      "179  5537670                                               None      Atomic   \n",
      "57    143242    0x0c15b61197c8fca4322b8e6c4a744b597622a1dc:base     Rarible   \n",
      "161  3756970    0x84f2789475754572311d65173ade3c24e643ba29:base     Rarible   \n",
      "33   4383665    0xffc20825c2d56c8eb4fee84bfd1be00465b84195:zora     OpenSea   \n",
      "48   3503331    0x97683a99e531201de43f68c445a0325a426ebf7c:celo     Rarible   \n",
      "69   5432956                                               None   MagicEden   \n",
      "11   5342669  0x7e85682473967164e300d8214f29b79989eacca7:arb...     OpenSea   \n",
      "189  5442205                                               None      Atomic   \n",
      "201  4807823  0xcccf5d0d43b3d49b1309e5170c6b33e072e13779:klaytn     OpenSea   \n",
      "85    628209    0x41ffb8407a23a1c1aa8b948677428e5049b850c1:base     Rarible   \n",
      "16   4757119  0x64424344db41ef208fe2ec3e0f9a72b7206b1a26:klaytn     OpenSea   \n",
      "119  5436649                                               None   MagicEden   \n",
      "28   3395441  0x482f1759dd48df2672c0b9a5fc6791b19f4fb7d3:eth...     Rarible   \n",
      "99   5416749                                               None   MagicEden   \n",
      "120  5431500                                               None   MagicEden   \n",
      "213    38703  0x7b25869dd5405b82b0debf48642eaca4e2a61a20:abs...     Rarible   \n",
      "84   5430081                                               None   MagicEden   \n",
      "106  3660530    0xbd88289d94f28cae7a5ea1136be8f78b863bb1cd:base     Rarible   \n",
      "81   4015392  0x5f5a2e9642d772a6d9b348621d0330ef0bc4222e:zksync     Rarible   \n",
      "212    45209  0xeeec1bda08cc5a6a26d43406c08d0d35bd54d830:abs...     Rarible   \n",
      "0    4411190  0x5bffbd52c28659fae69657f48dc20b119d39c86a:opt...     OpenSea   \n",
      "107   355547  0x68de02dab89a266858d74e2ca6707693fff022f16d9d...     Rarible   \n",
      "25   4434820   0x63d6b051505f2d05223924e53a8f68a9301f00ac:matic     OpenSea   \n",
      "50    785286  0x9fcd53e9d106ceb6212f11cd6a20522283c3af53:pol...     Rarible   \n",
      "138   710726    0x64378902d6afb97eb222d3a02cc1c146acfb1c0e:base     Rarible   \n",
      "128  4253660  0x063b4aee04fce4ba9ff5110406822e47cf9297cc:uni...     OpenSea   \n",
      "150  4493974   0x0979a9ea5c1aa6ec0df28708f74f85d17ef35e4f:matic     OpenSea   \n",
      "43   4416289  0x03c00b28497a18924cc2d8f3a4b81e12f53212a7:ape...     OpenSea   \n",
      "136  4297239  0xeb6a5434a922f1249a0d3e0ae6db8ed2adb3b0b0:son...     OpenSea   \n",
      "104  2885383  0x594824a3d6e5777b3c7cc202ad1050435aac7698:eth...     Rarible   \n",
      "127  5430971                                               None   MagicEden   \n",
      "26   5524723                                               None      Atomic   \n",
      "164    55332    0x2387084d7ef28b12babc80dca429b267967a33c2:base     Rarible   \n",
      "97   5420816                                               None   MagicEden   \n",
      "170  4715486   0xa8cf12aad8eeac33fbdd67597a8d8d063c52ad04:matic     OpenSea   \n",
      "\n",
      "                                         slug_name  \\\n",
      "31                          Happy Chinese New Year   \n",
      "39                                  mekaapes-blast   \n",
      "62                            spotted_lanternflies   \n",
      "77                           cincinnati-physicians   \n",
      "17                                     dump-pepe-5   \n",
      "179                                   nftartdesing   \n",
      "57                               115152's Follower   \n",
      "161                   Boogie Wonderland (Club RMX)   \n",
      "33                                zora-posts-21385   \n",
      "48   Response b90e12f1-73c8-4505-826d-243042f81354   \n",
      "69                                 kyoudai_spirits   \n",
      "11                     me-physical-collectibles-10   \n",
      "189                                   targetedby11   \n",
      "201                                      aaaaaa-26   \n",
      "85                                            CUTE   \n",
      "16                       giants-g-nine-2024-emblem   \n",
      "119                              solana_mecha_apes   \n",
      "28                                        Pi-Verse   \n",
      "99                                drip_genopets_s2   \n",
      "120                             pixelated_apes_dao   \n",
      "213                                        fhllhvg   \n",
      "84                                      De_Casinos   \n",
      "106                               Mr Miggles Remix   \n",
      "81                                  Peace on Earth   \n",
      "212                                        Not ABC   \n",
      "0                                 zora-posts-19156   \n",
      "107                           Martian Testnet52997   \n",
      "25                                         bbbdf-e   \n",
      "50                                            Inka   \n",
      "138                       Hanging with the gnomeis   \n",
      "128                                       mintak-2   \n",
      "150    lens-collect-profile-126134-publication-890   \n",
      "43                                      city-s-art   \n",
      "136                                    blueandpink   \n",
      "104                                  The Old House   \n",
      "127                                        moveman   \n",
      "26                                    alienwor1dsz   \n",
      "164                              291590's Follower   \n",
      "97                                 frostys_friends   \n",
      "170   lens-collect-profile-143257-publication-8280   \n",
      "\n",
      "                                             full_name  \\\n",
      "31                                            Untitled   \n",
      "39                               MekaApes by OogaVerse   \n",
      "62                     Spotted Lanternflies of the CCP   \n",
      "77                               Cincinnati Physicians   \n",
      "17                                           DUMP PEPE   \n",
      "179                                             NFTART   \n",
      "57                                            Untitled   \n",
      "161          Dj L-Banga - Boogie Wonderland (Club RMX)   \n",
      "33                                          Zora Posts   \n",
      "48                                            Untitled   \n",
      "69                                     Kyoudai Spirits   \n",
      "11                            ME Physical Collectibles   \n",
      "189  Targeted by Taylor’s john and Steph and Blount co   \n",
      "201                                             AAAAAA   \n",
      "85                                            Untitled   \n",
      "16                           Giants G-Nine 2024 Emblem   \n",
      "119                                  Solana Mecha Apes   \n",
      "28                                            Untitled   \n",
      "99                              Genopets DRIP Season 2   \n",
      "120                                 Pixelated Apes DAO   \n",
      "213                                           Untitled   \n",
      "84                                            DeCasino   \n",
      "106                                   Mr Miggles Remix   \n",
      "81                                      Peace on Earth   \n",
      "212                                           Untitled   \n",
      "0                                           Zora Posts   \n",
      "107                               Martian Testnet52997   \n",
      "25                                             bbbdf e   \n",
      "50                                                Inka   \n",
      "138                                           Untitled   \n",
      "128                                             mintak   \n",
      "150  Lens Collect | Profile #126134 - Publication #890   \n",
      "43                                          city's art   \n",
      "136                                        BlueAndPink   \n",
      "104                                      The Old House   \n",
      "127                                            MoveMan   \n",
      "26                                 Tree Forest on Neri   \n",
      "164                                           Untitled   \n",
      "97                                     Frostys Friends   \n",
      "170  Lens Collect | Profile #143257 - Publication #...   \n",
      "\n",
      "                                           description  \\\n",
      "31                                                       \n",
      "39   Launched in January 22 on Ethereum, the MekaAp...   \n",
      "62                            Invasive pieces of shit.   \n",
      "77                                                       \n",
      "17                                                       \n",
      "179                                                      \n",
      "57                                                       \n",
      "161  Created by Dj L-Banga on Sound. Leave a commen...   \n",
      "33         Create and connect onchain. https://zora.co   \n",
      "48                                                       \n",
      "69   Kyoudai was a utopia until an elder Guardian, ...   \n",
      "11   Are you ready for first tokenized physical col...   \n",
      "189                                                      \n",
      "201  Stake USDT and earn a 30% APY, plus receive an...   \n",
      "85                                                       \n",
      "16                                                       \n",
      "119  A collection of Solana Mecha Apes conquering t...   \n",
      "28                                                       \n",
      "99   A collection of Genopet cards redeemable for i...   \n",
      "120   777 Pixelated Apes Dao Come In Solana Blockchain   \n",
      "213                                                      \n",
      "84   first sports betting and casino platform on so...   \n",
      "106                  Pharmacist Miggles Available 24/7   \n",
      "81   Peace on Earth collection helps to make the wo...   \n",
      "212                                                      \n",
      "0          Create and connect onchain. https://zora.co   \n",
      "107                                                      \n",
      "25                                                       \n",
      "50                                                       \n",
      "138                                                      \n",
      "128                                                      \n",
      "150                                                      \n",
      "43   city's art\\n\\nMade with [NFTs2Me.com](https://...   \n",
      "136                                                      \n",
      "104                                                      \n",
      "127  The MoveMan NFT collection offers 5,000 distin...   \n",
      "26                                                       \n",
      "164                                                      \n",
      "97                                      First 333 free   \n",
      "170                                                      \n",
      "\n",
      "                        category token_standard   created_time  \\\n",
      "31                                       ERC721                  \n",
      "39                        gaming                    26/04/2024   \n",
      "62                [\"pfps\", null]                                 \n",
      "77                                                               \n",
      "17                                                               \n",
      "179                                              1616349787000   \n",
      "57                                       ERC721                  \n",
      "161                        music         ERC721                  \n",
      "33                                                               \n",
      "48                                       ERC721                  \n",
      "69               [\"pfp\", \"pfps\"]                                 \n",
      "11                                                               \n",
      "189                                              1657340563500   \n",
      "201                                                              \n",
      "85                           art         ERC721                  \n",
      "16                                                               \n",
      "119                     [\"pfps\"]                                 \n",
      "28                                      ERC1155                  \n",
      "99   [\"games\", \"virtual_worlds\"]                                 \n",
      "120              [\"art\", \"pfps\"]                                 \n",
      "213                                      ERC721                  \n",
      "84                [\"pfps\", null]                                 \n",
      "106                                     ERC1155                  \n",
      "81                                       ERC721                  \n",
      "212                                      ERC721                  \n",
      "0                                                                \n",
      "107                                       APTOS                  \n",
      "25                                                               \n",
      "50                                      ERC1155                  \n",
      "138                        music         ERC721                  \n",
      "128                                                              \n",
      "150                                                              \n",
      "43                                                               \n",
      "136                                                              \n",
      "104                                      ERC721                  \n",
      "127            [\"sports\", \"art\"]                                 \n",
      "26                                               1620706592000   \n",
      "164                                      ERC721                  \n",
      "97                      [\"pfps\"]                                 \n",
      "170                                                              \n",
      "\n",
      "                                             image_url  ... instagram_url  \\\n",
      "31                                                      ...                 \n",
      "39                                                      ...          None   \n",
      "62   https://nftstorage.link/ipfs/bafybeidk6uac3srx...  ...                 \n",
      "77                                                      ...                 \n",
      "17                                                      ...                 \n",
      "179                                                     ...          None   \n",
      "57   https://i.seadn.io/s/raw/files/19f9f090920392c...  ...                 \n",
      "161  https://i.seadn.io/s/raw/files/0280a601db1ed2e...  ...                 \n",
      "33   https://i.seadn.io/s/raw/files/4c536bcb1411e0a...  ...                 \n",
      "48                                                      ...                 \n",
      "69   https://bafybeigbgifbgkobfwqb5wirim2ktznsukusv...  ...                 \n",
      "11   https://i.seadn.io/s/raw/files/1a53754bc10ca79...  ...                 \n",
      "189                                                     ...          None   \n",
      "201  https://i.seadn.io/s/raw/files/dfca9770398d2d8...  ...                 \n",
      "85   https://i.seadn.io/s/raw/files/ca59e3a2d84c1e7...  ...                 \n",
      "16   https://i.seadn.io/s/raw/files/6522b559b0dded1...  ...                 \n",
      "119  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "28                                                      ...                 \n",
      "99   https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "120  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "213                                                     ...                 \n",
      "84   https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "106  https://i.seadn.io/s/raw/files/1b8f55d7faf6099...  ...                 \n",
      "81                                                      ...                 \n",
      "212                                                     ...                 \n",
      "0    https://i.seadn.io/s/raw/files/2d156a21e00b779...  ...                 \n",
      "107                                                     ...                 \n",
      "25   https://i.seadn.io/s/raw/files/fc977d71226fdcd...  ...                 \n",
      "50                                                      ...                 \n",
      "138  https://i.seadn.io/s/raw/files/bad49ba1ae8628f...  ...                 \n",
      "128                                                     ...                 \n",
      "150                                                     ...                 \n",
      "43   https://i.seadn.io/s/raw/files/9186d2e11295ffb...  ...                 \n",
      "136  https://raw.seadn.io/files/9c86447a06387c6b97c...  ...                 \n",
      "104                                                     ...                 \n",
      "127  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "26                                                      ...          None   \n",
      "164  https://i.seadn.io/s/raw/files/19f9f090920392c...  ...                 \n",
      "97   https://nftstorage.link/ipfs/bafybeihabhdegrpx...  ...                 \n",
      "170                                                     ...                 \n",
      "\n",
      "    facebook_url                       discord_url telegram_url  \\\n",
      "31                                                                \n",
      "39                 https://discord.gg/oogaversenft         None   \n",
      "62                                                                \n",
      "77                                                                \n",
      "17                                                                \n",
      "179         None                              None         None   \n",
      "57                                                                \n",
      "161                                                               \n",
      "33                                                                \n",
      "48                                                                \n",
      "69                                                                \n",
      "11                                                                \n",
      "189                                                               \n",
      "201                                                               \n",
      "85                                                                \n",
      "16                                                                \n",
      "119                                                               \n",
      "28                                                                \n",
      "99                 https://www.discord.gg/genopets                \n",
      "120                https://www.discord.gg/puUeKTgg                \n",
      "213                                                               \n",
      "84                https://www.discord.gg/decasinos                \n",
      "106                                                               \n",
      "81                                                                \n",
      "212                                                               \n",
      "0                                                                 \n",
      "107                                                               \n",
      "25                                                                \n",
      "50                                                                \n",
      "138                                                               \n",
      "128                                                               \n",
      "150                                                               \n",
      "43                                                                \n",
      "136                                                               \n",
      "104                                                               \n",
      "127                 https://www.discord.gg/moveman                \n",
      "26          None                              None         None   \n",
      "164                                                               \n",
      "97                                                                \n",
      "170                                                               \n",
      "\n",
      "    marketplace_fee royalty_fee  marketplace_stratum  blockchain_stratum  \\\n",
      "31              NaN         NaN                 None               match   \n",
      "39             2.50         7.5                 None                None   \n",
      "62              NaN         NaN            MagicEden                None   \n",
      "77              NaN         NaN              OpenSea                None   \n",
      "17              NaN         NaN                 None           ape_chain   \n",
      "179            0.05         NaN               Atomic                None   \n",
      "57              NaN         NaN                 None                None   \n",
      "161             NaN         NaN                 None                None   \n",
      "33              NaN         NaN              OpenSea                None   \n",
      "48              NaN         NaN                 None                celo   \n",
      "69              NaN         NaN                 None                None   \n",
      "11              NaN         NaN                 None       arbitrum_nova   \n",
      "189            0.06         NaN               Atomic                None   \n",
      "201             NaN         NaN                 None              klaytn   \n",
      "85              NaN         NaN                 None                None   \n",
      "16              NaN         NaN                 None              klaytn   \n",
      "119             NaN         NaN            MagicEden                None   \n",
      "28              NaN         NaN                 None           etherlink   \n",
      "99              NaN         NaN                 None                None   \n",
      "120             NaN         NaN            MagicEden                None   \n",
      "213             NaN         NaN                 None            abstract   \n",
      "84              NaN         NaN            MagicEden                None   \n",
      "106             NaN         NaN                 None                base   \n",
      "81              NaN         NaN                 None              zksync   \n",
      "212             NaN         NaN                 None            abstract   \n",
      "0               NaN         NaN                 None            optimism   \n",
      "107             NaN         NaN                 None                None   \n",
      "25              NaN         NaN              OpenSea                None   \n",
      "50              NaN         NaN                 None                None   \n",
      "138             NaN         NaN                 None                None   \n",
      "128             NaN         NaN                 None            unichain   \n",
      "150             NaN         NaN              OpenSea                None   \n",
      "43              NaN         NaN              OpenSea                None   \n",
      "136             NaN         NaN                 None             soneium   \n",
      "104             NaN         NaN              Rarible                None   \n",
      "127             NaN         NaN                 None                None   \n",
      "26             0.05         NaN               Atomic                None   \n",
      "164             NaN         NaN              Rarible                None   \n",
      "97              NaN         NaN            MagicEden                None   \n",
      "170             NaN         NaN              OpenSea                None   \n",
      "\n",
      "    category_stratum token_standard_stratum  \n",
      "31              None                   None  \n",
      "39            gaming                   None  \n",
      "62              None                   None  \n",
      "77              None                   None  \n",
      "17              None                   None  \n",
      "179             None                   None  \n",
      "57              None                 erc721  \n",
      "161            music                   None  \n",
      "33              None                   None  \n",
      "48              None                   None  \n",
      "69               pfp                   None  \n",
      "11              None                   None  \n",
      "189             None                   None  \n",
      "201             None                   None  \n",
      "85               art                   None  \n",
      "16              None                   None  \n",
      "119             None                   None  \n",
      "28              None                   None  \n",
      "99    virtual_worlds                   None  \n",
      "120             None                   None  \n",
      "213             None                   None  \n",
      "84              None                   None  \n",
      "106             None                   None  \n",
      "81              None                   None  \n",
      "212             None                   None  \n",
      "0               None                   None  \n",
      "107             None                  aptos  \n",
      "25              None                   None  \n",
      "50              None                erc1155  \n",
      "138            music                   None  \n",
      "128             None                   None  \n",
      "150             None                   None  \n",
      "43              None                   None  \n",
      "136             None                   None  \n",
      "104             None                   None  \n",
      "127           sports                   None  \n",
      "26              None                   None  \n",
      "164             None                   None  \n",
      "97              None                   None  \n",
      "170             None                   None  \n",
      "\n",
      "[40 rows x 22 columns]' in table 'sampled_collections'.\n"
     ]
    }
   ],
   "source": [
    "draw_fifth_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table: opensea_nfts\n",
      "Dropped table: rarible_nfts\n",
      "Dropped table: magiceden_nfts\n",
      "Dropped table: atomic_nfts\n",
      "All tables except 'sampled_collections' and 'sqlite_sequence' have been dropped from 'random_sample_5.db'.\n"
     ]
    }
   ],
   "source": [
    "def drop_other_tables(db_path=\"random_sample_5.db\", keep_table=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Connects to 'db_path', enumerates all tables, \n",
    "    and drops any table that is not 'keep_table' or 'sqlite_sequence'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 1) Get all tables in the SQLite file\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    # 2) For each table, if it's not keep_table or 'sqlite_sequence', drop it\n",
    "    for tbl in tables:\n",
    "        if tbl not in [keep_table, \"sqlite_sequence\"]:\n",
    "            drop_sql = f\"DROP TABLE IF EXISTS '{tbl}'\"\n",
    "            cursor.execute(drop_sql)\n",
    "            print(f\"Dropped table: {tbl}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"All tables except '{keep_table}' and 'sqlite_sequence' have been dropped from '{db_path}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    drop_other_tables(db_path=\"random_sample_5.db\", keep_table=\"sampled_collections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opensea_nfts_table(db_path=\"random_sample_5.db\", table_name=\"opensea_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table with columns for the relevant fields from the OpenSea NFT JSON.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Create table if not exists\n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        \n",
    "        -- Linking field from 'sampled_collections' table\n",
    "        slug_name TEXT,\n",
    "        \n",
    "        -- Fields from the NFT JSON:\n",
    "        identifier TEXT,\n",
    "        contract TEXT,\n",
    "        token_standard TEXT,\n",
    "        name TEXT,\n",
    "        description TEXT,\n",
    "        image_url TEXT,\n",
    "        display_image_url TEXT,\n",
    "        display_animation_url TEXT,\n",
    "        metadata_url TEXT,\n",
    "        opensea_url TEXT,\n",
    "        updated_at TEXT,\n",
    "        is_disabled INTEGER,\n",
    "        is_nsfw INTEGER,\n",
    "        \n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_opensea_nfts(collection_slug, api_key, limit=10):\n",
    "    \"\"\"\n",
    "    Calls the OpenSea endpoint:\n",
    "      GET /api/v2/collection/{collection_slug}/nfts?limit={limit}\n",
    "    Returns the parsed JSON dict with:\n",
    "       { \"nfts\": [ { ... }, {...} ], \"next\": \"string\" }\n",
    "    If there's an error, returns an empty dict.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.opensea.io/api/v2/collection\"\n",
    "    url = f\"{base_url}/{collection_slug}/nfts\"\n",
    "    \n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": api_key\n",
    "    }\n",
    "    params = {\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    \n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[OpenSea NFT Fetch] Error {resp.status_code} for '{collection_slug}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def store_opensea_nfts(db_path, table_name, slug_name, nfts_data):\n",
    "    \"\"\"\n",
    "    Inserts each NFT from nfts_data[\"nfts\"] into opensea_nfts, linking them\n",
    "    via 'slug_name'. We do NOT store the 'collection' field from the JSON,\n",
    "    but instead rely on 'slug_name' to identify the parent collection.\n",
    "    \"\"\"\n",
    "    nfts_list = nfts_data.get(\"nfts\", [])\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        slug_name,\n",
    "        identifier,\n",
    "        contract,\n",
    "        token_standard,\n",
    "        name,\n",
    "        description,\n",
    "        image_url,\n",
    "        display_image_url,\n",
    "        display_animation_url,\n",
    "        metadata_url,\n",
    "        opensea_url,\n",
    "        updated_at,\n",
    "        is_disabled,\n",
    "        is_nsfw,\n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))\n",
    "    \"\"\"\n",
    "    \n",
    "    for nft in nfts_list:\n",
    "        identifier = nft.get(\"identifier\", \"\")\n",
    "        contract = nft.get(\"contract\", \"\")\n",
    "        token_standard = nft.get(\"token_standard\", \"\")\n",
    "        name = nft.get(\"name\", \"\")\n",
    "        desc = nft.get(\"description\", \"\")\n",
    "        image_url = nft.get(\"image_url\", \"\")\n",
    "        display_image = nft.get(\"display_image_url\", \"\")\n",
    "        display_animation = nft.get(\"display_animation_url\", \"\")\n",
    "        metadata_url = nft.get(\"metadata_url\", \"\")\n",
    "        opensea_url = nft.get(\"opensea_url\", \"\")\n",
    "        updated_at = nft.get(\"updated_at\", \"\")\n",
    "        \n",
    "        # Convert booleans to int (1/0)\n",
    "        is_disabled = 1 if nft.get(\"is_disabled\", False) else 0\n",
    "        is_nsfw = 1 if nft.get(\"is_nsfw\", False) else 0\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            slug_name,\n",
    "            identifier,\n",
    "            contract,\n",
    "            token_standard,\n",
    "            name,\n",
    "            desc,\n",
    "            image_url,\n",
    "            display_image,\n",
    "            display_animation,\n",
    "            metadata_url,\n",
    "            opensea_url,\n",
    "            updated_at,\n",
    "            is_disabled,\n",
    "            is_nsfw\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def fetch_opensea_nfts_for_collections(db_path=\"random_sample_5.db\", table_collections=\"sampled_collections\",\n",
    "                                       table_nfts=\"opensea_nfts\", api_key=\"YOUR_API_KEY\", limit=10):\n",
    "    \"\"\"\n",
    "    1) Ensure 'opensea_nfts' table exists.\n",
    "    2) Query 'sampled_collections' for marketplace='OpenSea', using 'slug_name'\n",
    "    3) For each, fetch up to {limit} items from OpenSea.\n",
    "    4) Store them in 'opensea_nfts'.\n",
    "    \"\"\"\n",
    "    # Create table if not exists\n",
    "    create_opensea_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Query the relevant rows\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    for idx, (slug,) in enumerate(rows, start=1):\n",
    "        print(f\"[{idx}/{len(rows)}] Fetching up to {limit} NFTs for slug='{slug}'\")\n",
    "        nfts_data = fetch_opensea_nfts(slug, api_key, limit=limit)\n",
    "        store_opensea_nfts(db_path, table_nfts, slug, nfts_data)\n",
    "    \n",
    "    print(\"Done fetching NFT data for all OpenSea collections in random_sample_5.db.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/14] Fetching up to 10 NFTs for slug='mekaapes-blast'\n",
      "[2/14] Fetching up to 10 NFTs for slug='cincinnati-physicians'\n",
      "[3/14] Fetching up to 10 NFTs for slug='dump-pepe-5'\n",
      "[4/14] Fetching up to 10 NFTs for slug='zora-posts-21385'\n",
      "[5/14] Fetching up to 10 NFTs for slug='me-physical-collectibles-10'\n",
      "[6/14] Fetching up to 10 NFTs for slug='aaaaaa-26'\n",
      "[7/14] Fetching up to 10 NFTs for slug='giants-g-nine-2024-emblem'\n",
      "[8/14] Fetching up to 10 NFTs for slug='zora-posts-19156'\n",
      "[9/14] Fetching up to 10 NFTs for slug='bbbdf-e'\n",
      "[10/14] Fetching up to 10 NFTs for slug='mintak-2'\n",
      "[11/14] Fetching up to 10 NFTs for slug='lens-collect-profile-126134-publication-890'\n",
      "[12/14] Fetching up to 10 NFTs for slug='city-s-art'\n",
      "[13/14] Fetching up to 10 NFTs for slug='blueandpink'\n",
      "[14/14] Fetching up to 10 NFTs for slug='lens-collect-profile-143257-publication-8280'\n",
      "Done fetching NFT data for all OpenSea collections in random_sample_5.db.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENSEA_API_KEY = \"your_key\"\n",
    "    fetch_opensea_nfts_for_collections(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"opensea_nfts\",\n",
    "        api_key=OPENSEA_API_KEY,\n",
    "        limit=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_columns_if_not_exists(db_path=\"random_sample_5.db\", table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Adds the column 'total_supply' to the 'sampled_collections' table\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    cols_to_add = [\n",
    "        (\"total_supply\", \"REAL\")\n",
    "    ]\n",
    "    \n",
    "    for col, col_type in cols_to_add:\n",
    "        alter_stmt = f\"ALTER TABLE {table_name} ADD COLUMN {col} {col_type}\"\n",
    "        try:\n",
    "            c.execute(alter_stmt)\n",
    "            print(f\"Added column '{col}' to {table_name}\")\n",
    "        except sqlite3.OperationalError as e:\n",
    "            # Likely column already exists\n",
    "            pass\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_opensea_collection_details(slug, api_key):\n",
    "    \"\"\"\n",
    "    Calls the endpoint:\n",
    "      GET https://api.opensea.io/api/v2/collections/{collection_slug}\n",
    "    Returns a dict with keys:\n",
    "       'collection', 'name', 'total_supply', 'created_date', 'fees' (list), etc.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.opensea.io/api/v2/collections/{slug}\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": api_key\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json() \n",
    "    else:\n",
    "        print(f\"[OpenSea Collection Fetch] Error {resp.status_code} for slug='{slug}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def update_opensea_collection_data(db_path, table_name, slug, data):\n",
    "    \"\"\"\n",
    "    data has: 'created_date', 'total_supply', 'fees' list, etc.\n",
    "    We map:\n",
    "       created_date -> created_time\n",
    "       total_supply -> total_supply\n",
    "       fees[0].fee -> marketplace_fee\n",
    "       fees[1].fee -> royalty_fee (if exist)\n",
    "    Then do UPDATE on the row with marketplace='OpenSea' AND slug_name=?\n",
    "    \"\"\"\n",
    "    collection_slug = data.get(\"collection\", slug)  # fallback to slug if missing\n",
    "    created_date = data.get(\"created_date\", None)   # string\n",
    "    total_supply = data.get(\"total_supply\", 0.0)\n",
    "    fees = data.get(\"fees\", [])\n",
    "    \n",
    "    marketplace_fee = None\n",
    "    royalty_fee = None\n",
    "    \n",
    "    if len(fees) >= 1:\n",
    "        # first fee => marketplace fee\n",
    "        marketplace_fee = fees[0].get(\"fee\", 0.0)\n",
    "    if len(fees) >= 2:\n",
    "        # second fee => royalty fee\n",
    "        royalty_fee = fees[1].get(\"fee\", 0.0)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    update_stmt = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET created_time = ?,\n",
    "        total_supply = ?,\n",
    "        marketplace_fee = ?,\n",
    "        royalty_fee = ?\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name=?\n",
    "    \"\"\"\n",
    "    c.execute(update_stmt, (\n",
    "        created_date,\n",
    "        total_supply,\n",
    "        marketplace_fee,\n",
    "        royalty_fee,\n",
    "        slug\n",
    "    ))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_and_update_opensea_collection_data(db_path=\"random_sample_5.db\", table_name=\"sampled_collections\",\n",
    "                                             api_key=\"YOUR_API_KEY\"):\n",
    "    \"\"\"\n",
    "    # 1) Ensure the new columns exist in the 'sampled_collections' table.\n",
    "    # 2) Query all rows for marketplace='OpenSea'.\n",
    "    # 3) For each slug_name, call the new endpoint to fetch additional data,\n",
    "    #    then update the row with created_time, total_supply, marketplace_fee, royalty_fee.\n",
    "    # \"\"\"\n",
    "\n",
    "    add_new_columns_if_not_exists()\n",
    "    \n",
    "    # 2) Query the existing table\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "        SELECT slug_name\n",
    "        FROM {table_name}\n",
    "        WHERE marketplace='OpenSea'\n",
    "          AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    for idx, (slug,) in enumerate(rows, start=1):\n",
    "        print(f\"[{idx}/{len(rows)}] Fetching extended data for slug='{slug}'\")\n",
    "        data = fetch_opensea_collection_details(slug, api_key)\n",
    "        if data:\n",
    "            # parse JSON: top-level fields => data\n",
    "            # The endpoint returns { \"collection\": \"string\", \"name\": \"string\", ...}\n",
    "            # We just pass it to update\n",
    "            update_opensea_collection_data(db_path, table_name, slug, data)\n",
    "            \n",
    "        # optional short sleep to avoid rate-limiting\n",
    "        # time.sleep(0.2)\n",
    "\n",
    "    print(\"Done updating additional data for all OpenSea collections in random_sample_5.db.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added column 'total_supply' to sampled_collections\n",
      "[1/14] Fetching extended data for slug='mekaapes-blast'\n",
      "[2/14] Fetching extended data for slug='cincinnati-physicians'\n",
      "[3/14] Fetching extended data for slug='dump-pepe-5'\n",
      "[4/14] Fetching extended data for slug='zora-posts-21385'\n",
      "[5/14] Fetching extended data for slug='me-physical-collectibles-10'\n",
      "[6/14] Fetching extended data for slug='aaaaaa-26'\n",
      "[7/14] Fetching extended data for slug='giants-g-nine-2024-emblem'\n",
      "[8/14] Fetching extended data for slug='zora-posts-19156'\n",
      "[9/14] Fetching extended data for slug='bbbdf-e'\n",
      "[10/14] Fetching extended data for slug='mintak-2'\n",
      "[11/14] Fetching extended data for slug='lens-collect-profile-126134-publication-890'\n",
      "[12/14] Fetching extended data for slug='city-s-art'\n",
      "[13/14] Fetching extended data for slug='blueandpink'\n",
      "[14/14] Fetching extended data for slug='lens-collect-profile-143257-publication-8280'\n",
      "Done updating additional data for all OpenSea collections in random_sample_5.db.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENSEA_API_KEY = \"your_key\"\n",
    "    fetch_and_update_opensea_collection_data(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_name=\"sampled_collections\",\n",
    "        api_key=OPENSEA_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_traits_json_column_if_not_exists(db_path=\"random_sample_5.db\", table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Adds a 'traits_json' column to the 'sampled_collections' table if it does not exist.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Attempt an ALTER TABLE for 'traits_json'\n",
    "    alter_stmt = f\"ALTER TABLE {table_name} ADD COLUMN traits_json TEXT\"\n",
    "    try:\n",
    "        c.execute(alter_stmt)\n",
    "        print(f\"Added 'traits_json' column to {table_name}\")\n",
    "    except sqlite3.OperationalError:\n",
    "        # Column probably already exists\n",
    "        pass\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_opensea_traits(collection_slug, api_key):\n",
    "    \"\"\"\n",
    "    Calls the OpenSea endpoint:\n",
    "    GET /api/v2/traits/{collection_slug}\n",
    "    \n",
    "    Returns JSON like:\n",
    "      {\n",
    "        \"categories\": {...},\n",
    "        \"counts\": {...}\n",
    "      }\n",
    "    \"\"\"\n",
    "    url = f\"https://api.opensea.io/api/v2/traits/{collection_slug}\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": api_key\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[OpenSea Traits] Error {resp.status_code} for slug='{collection_slug}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def store_traits_json_in_collections(db_path, table_name, slug_name, traits_data):\n",
    "    \"\"\"\n",
    "    Updates the 'sampled_collections' table with the entire traits JSON\n",
    "    in the 'traits_json' column for the given slug_name.\n",
    "    \n",
    "    We assume marketplace='OpenSea' is the row filter.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    update_stmt = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET traits_json = ?\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name=?\n",
    "    \"\"\"\n",
    "    c.execute(update_stmt, (json.dumps(traits_data), slug_name))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def fetch_and_update_opensea_traits_in_collections(db_path=\"random_sample_5.db\",\n",
    "                                                   table_name=\"sampled_collections\",\n",
    "                                                   api_key=\"YOUR_API_KEY\"):\n",
    "    \"\"\"\n",
    "    1) Ensure 'traits_json' column exists in 'sampled_collections'.\n",
    "    2) Query all rows where marketplace='OpenSea' and slug_name is not null.\n",
    "    3) For each slug_name, fetch traits JSON from /api/v2/traits/{slug_name} and\n",
    "       store it in the 'traits_json' column.\n",
    "    \"\"\"\n",
    "    # 1) Add 'traits_json' column if needed\n",
    "    add_traits_json_column_if_not_exists(db_path, table_name)\n",
    "    \n",
    "    # 2) Query the existing table for OpenSea slugs\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    # 3) For each slug, fetch traits and store\n",
    "    for idx, (slug,) in enumerate(rows, start=1):\n",
    "        print(f\"[{idx}/{len(rows)}] Fetching traits for slug='{slug}'\")\n",
    "        traits_data = fetch_opensea_traits(slug, api_key)\n",
    "        store_traits_json_in_collections(db_path, table_name, slug, traits_data)\n",
    "    \n",
    "    print(f\"Done updating 'traits_json' for all OpenSea collections in {table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'traits_json' column to sampled_collections\n",
      "[1/14] Fetching traits for slug='mekaapes-blast'\n",
      "[2/14] Fetching traits for slug='cincinnati-physicians'\n",
      "[3/14] Fetching traits for slug='dump-pepe-5'\n",
      "[4/14] Fetching traits for slug='zora-posts-21385'\n",
      "[5/14] Fetching traits for slug='me-physical-collectibles-10'\n",
      "[6/14] Fetching traits for slug='aaaaaa-26'\n",
      "[7/14] Fetching traits for slug='giants-g-nine-2024-emblem'\n",
      "[8/14] Fetching traits for slug='zora-posts-19156'\n",
      "[9/14] Fetching traits for slug='bbbdf-e'\n",
      "[10/14] Fetching traits for slug='mintak-2'\n",
      "[11/14] Fetching traits for slug='lens-collect-profile-126134-publication-890'\n",
      "[12/14] Fetching traits for slug='city-s-art'\n",
      "[13/14] Fetching traits for slug='blueandpink'\n",
      "[14/14] Fetching traits for slug='lens-collect-profile-143257-publication-8280'\n",
      "Done updating 'traits_json' for all OpenSea collections in sampled_collections.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENSEA_API_KEY = \"your_key\"\n",
    "    fetch_and_update_opensea_traits_in_collections(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_name=\"sampled_collections\",\n",
    "        api_key=OPENSEA_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rarible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_collection_id(collection_id_blockchain):\n",
    "    \"\"\"\n",
    "    Given a string like '0x594824a3d6e5777b3c7cc202ad1050435aac7698:ethereum',\n",
    "    transform it into 'ETHEREUM:0x594824a3d6e5777b3c7cc202ad1050435aac7698'\n",
    "    for Rarible's endpoint: ?collectionIds=ETHEREUM%3A0x..\n",
    "    \"\"\"\n",
    "    if \":\" not in collection_id_blockchain:\n",
    "        return None\n",
    "    coll_id, chain = collection_id_blockchain.split(\":\")\n",
    "    return f\"{chain.upper()}:{coll_id}\"\n",
    "\n",
    "def fetch_rarible_traits_single(collection_id_rarible, api_key):\n",
    "    \"\"\"\n",
    "    Calls Rarible's endpoint, single collection ID:\n",
    "      GET /v0.1/items/traits?collectionIds={collection_id_rarible}\n",
    "\n",
    "    Returns the JSON with structure:\n",
    "      {\n",
    "        \"continuation\": \"string\",\n",
    "        \"traits\": [ { \"key\": {...}, \"values\": [...] }, ... ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.rarible.org/v0.1/items/traits\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"X-API-KEY\": api_key\n",
    "    }\n",
    "    # For a single ID, just pass collectionIds once\n",
    "    params = {\n",
    "        \"collectionIds\": collection_id_rarible\n",
    "    }\n",
    "    resp = requests.get(base_url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[Rarible Traits] Error {resp.status_code} => {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def update_traits_json_for_rarible(db_path=\"random_sample_5.db\",\n",
    "                                   table_name=\"sampled_collections\",\n",
    "                                   api_key=\"YOUR_RARIBLE_API_KEY\"):\n",
    "    \"\"\"\n",
    "    1) Query 'sampled_collections' where marketplace='Rarible'\n",
    "    2) For each row, transform 'collection_id' to Rarible format, fetch traits,\n",
    "       store entire JSON in 'traits_json' column\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # We'll assume 'traits_json' column already exists (like for OpenSea).\n",
    "    # If not, you'll need the add_column logic from your previous script.\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    SELECT collection_id\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='Rarible'\n",
    "      AND collection_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} Rarible collections to fetch traits for.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (orig_id,) in rows:\n",
    "        rarible_id = transform_collection_id(orig_id)\n",
    "        if rarible_id is None:\n",
    "            print(f\"Skipping invalid format => {orig_id}\")\n",
    "            continue\n",
    "        \n",
    "        data = fetch_rarible_traits_single(rarible_id, api_key)\n",
    "        \n",
    "        # Now update the 'traits_json' in that row\n",
    "        conn2 = sqlite3.connect(db_path)\n",
    "        c2 = conn2.cursor()\n",
    "        update_stmt = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET traits_json = ?\n",
    "        WHERE marketplace='Rarible'\n",
    "          AND collection_id=?\n",
    "        \"\"\"\n",
    "        c2.execute(update_stmt, (json.dumps(data), orig_id))\n",
    "        conn2.commit()\n",
    "        conn2.close()\n",
    "        \n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Updated 'traits_json' for => {orig_id}\")\n",
    "    \n",
    "    print(\"Done fetching/storing Rarible traits in 'traits_json' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 Rarible collections to fetch traits for.\n",
      "[1/15] Updated 'traits_json' for => 0x716ad1b6222046289c1664825cd9e4caf6253aec:match\n",
      "[2/15] Updated 'traits_json' for => 0x0c15b61197c8fca4322b8e6c4a744b597622a1dc:base\n",
      "[3/15] Updated 'traits_json' for => 0x84f2789475754572311d65173ade3c24e643ba29:base\n",
      "[4/15] Updated 'traits_json' for => 0x97683a99e531201de43f68c445a0325a426ebf7c:celo\n",
      "[5/15] Updated 'traits_json' for => 0x41ffb8407a23a1c1aa8b948677428e5049b850c1:base\n",
      "[6/15] Updated 'traits_json' for => 0x482f1759dd48df2672c0b9a5fc6791b19f4fb7d3:etherlink\n",
      "[7/15] Updated 'traits_json' for => 0x7b25869dd5405b82b0debf48642eaca4e2a61a20:abstract\n",
      "[8/15] Updated 'traits_json' for => 0xbd88289d94f28cae7a5ea1136be8f78b863bb1cd:base\n",
      "[9/15] Updated 'traits_json' for => 0x5f5a2e9642d772a6d9b348621d0330ef0bc4222e:zksync\n",
      "[10/15] Updated 'traits_json' for => 0xeeec1bda08cc5a6a26d43406c08d0d35bd54d830:abstract\n",
      "[11/15] Updated 'traits_json' for => 0x68de02dab89a266858d74e2ca6707693fff022f16d9d9020f52e08271acade84:aptos\n",
      "[12/15] Updated 'traits_json' for => 0x9fcd53e9d106ceb6212f11cd6a20522283c3af53:polygon\n",
      "[13/15] Updated 'traits_json' for => 0x64378902d6afb97eb222d3a02cc1c146acfb1c0e:base\n",
      "[14/15] Updated 'traits_json' for => 0x594824a3d6e5777b3c7cc202ad1050435aac7698:ethereum\n",
      "[15/15] Updated 'traits_json' for => 0x2387084d7ef28b12babc80dca429b267967a33c2:base\n",
      "Done fetching/storing Rarible traits in 'traits_json' column.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    RARIBLE_API_KEY = \"your_key\"\n",
    "    update_traits_json_for_rarible(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_name=\"sampled_collections\",\n",
    "        api_key=RARIBLE_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rarible_nfts_table(db_path=\"random_sample_5.db\", table_name=\"rarible_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table 'rarible_nfts' with columns similar to 'opensea_nfts',\n",
    "    storing key fields from the Rarible item-level data plus a link back \n",
    "    to 'collection_id' in 'sampled_collections'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        -- references the original 'id:blockchain' format from 'sampled_collections'\n",
    "        collection_id TEXT,\n",
    "        \n",
    "        item_id TEXT,          -- item[\"id\"] e.g. \"ETHEREUM:0xb66a6...:123\"\n",
    "        blockchain TEXT,       -- item[\"blockchain\"]\n",
    "        contract TEXT,         -- item[\"contract\"]\n",
    "        token_id TEXT,         -- item[\"tokenId\"]\n",
    "        \n",
    "        name TEXT,             -- from item[\"meta\"][\"name\"]\n",
    "        description TEXT,      -- from item[\"meta\"][\"description\"]\n",
    "        image_url TEXT,        -- optional, if we parse item[\"meta\"][\"content\"] for an image\n",
    "        minted_at TEXT,        -- item[\"mintedAt\"]\n",
    "        last_updated TEXT,     -- item[\"lastUpdatedAt\"]\n",
    "        supply REAL,           -- item[\"supply\"] \n",
    "        owner_if_single TEXT,  -- item[\"ownerIfSingle\"] if we want\n",
    "        \n",
    "        project_url TEXT,      -- e.g. item[\"meta\"][\"externalUri\"] if present\n",
    "        created_at TEXT,       -- item[\"meta\"][\"createdAt\"]\n",
    "        \n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_collection_id_for_rarible(orig_id):\n",
    "    \"\"\"\n",
    "    Convert 'id:blockchain' => 'BLOCKCHAIN:0xid' for use in Rarible API.\n",
    "    e.g. '0x5948abcd:ethereum' => 'ETHEREUM:0x5948abcd'\n",
    "    \"\"\"\n",
    "    if \":\" not in orig_id:\n",
    "        return None\n",
    "    coll_id, chain = orig_id.split(\":\")\n",
    "    return f\"{chain.upper()}:{coll_id}\"\n",
    "\n",
    "def fetch_rarible_nfts(collection_param, api_key, size=10):\n",
    "    \"\"\"\n",
    "    Calls Rarible endpoint:\n",
    "      GET /v0.1/items/byCollection?collection={collection_param}&size={size}\n",
    "    e.g. collection_param = 'ETHEREUM:0xb66a603f...'\n",
    "    Returns a dict with keys 'continuation' and 'items' (list).\n",
    "    \"\"\"\n",
    "    url = \"https://api.rarible.org/v0.1/items/byCollection\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"X-API-KEY\": api_key\n",
    "    }\n",
    "    params = {\n",
    "        \"collection\": collection_param,\n",
    "        \"size\": size\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[Rarible NFT Fetch] Error {resp.status_code} => {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def store_rarible_nfts(db_path, table_name, orig_id, items_list):\n",
    "    \"\"\"\n",
    "    Insert up to 10 items into 'rarible_nfts' table, storing relevant fields.\n",
    "    :param orig_id: The original 'id:blockchain' used in 'sampled_collections'\n",
    "    :param items_list: list of item dicts from the Rarible API\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        collection_id,\n",
    "        item_id,\n",
    "        blockchain,\n",
    "        contract,\n",
    "        token_id,\n",
    "        name,\n",
    "        description,\n",
    "        image_url,\n",
    "        minted_at,\n",
    "        last_updated,\n",
    "        supply,\n",
    "        owner_if_single,\n",
    "        project_url,\n",
    "        created_at,\n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in items_list:\n",
    "        item_id = item.get(\"id\", \"\")\n",
    "        blockchain = item.get(\"blockchain\", \"\")\n",
    "        contract = item.get(\"contract\", \"\")\n",
    "        token_id = str(item.get(\"tokenId\", \"\"))\n",
    "        supply = item.get(\"supply\", 0)\n",
    "        minted_at = item.get(\"mintedAt\", \"\")\n",
    "        last_updated = item.get(\"lastUpdatedAt\", \"\")\n",
    "        owner_if_single = item.get(\"ownerIfSingle\", \"\")\n",
    "        \n",
    "        meta = item.get(\"meta\", {})\n",
    "        name = meta.get(\"name\", \"\")\n",
    "        description = meta.get(\"description\", \"\")\n",
    "        created_at = meta.get(\"createdAt\", \"\")\n",
    "        project_url = meta.get(\"externalUri\", \"\")\n",
    "        \n",
    "        # Optional: parse meta[\"content\"] for image\n",
    "        # The example doesn't show a direct \"url\", so we may store 'N/A' or parse further\n",
    "        content_list = meta.get(\"content\", [])\n",
    "        image_url = \"N/A\"\n",
    "        for content_obj in content_list:\n",
    "            # if there's a recognized URL, parse it\n",
    "            # The example lacks a 'url' field, so we skip. \n",
    "            # If your real data has it, you might do:\n",
    "            # image_url = content_obj.get(\"url\", \"N/A\")\n",
    "            # break\n",
    "            pass\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            orig_id,      # collection_id (as it appears in 'sampled_collections')\n",
    "            item_id,\n",
    "            blockchain,\n",
    "            contract,\n",
    "            token_id,\n",
    "            name,\n",
    "            description,\n",
    "            image_url,\n",
    "            minted_at,\n",
    "            last_updated,\n",
    "            supply,\n",
    "            owner_if_single,\n",
    "            project_url,\n",
    "            created_at\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_rarible_nfts_for_collections(db_path=\"random_sample_5.db\", table_collections=\"sampled_collections\",\n",
    "                                       table_nfts=\"rarible_nfts\", api_key=\"YOUR_RARIBLE_API_KEY\", size=10):\n",
    "    \"\"\"\n",
    "    1) Create the 'rarible_nfts' table if not exists.\n",
    "    2) Query 'sampled_collections' where marketplace='Rarible'.\n",
    "    3) Transform 'collection_id:blockchain' to 'BLOCKCHAIN:collection_id'.\n",
    "    4) Fetch items (size=10) from Rarible's endpoint.\n",
    "    5) Store them in 'rarible_nfts'.\n",
    "    \"\"\"\n",
    "    # 1) create table\n",
    "    create_rarible_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    # 2) query the relevant rows\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT collection_id\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='Rarible'\n",
    "      AND collection_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    count = 0\n",
    "    for (orig_id,) in rows:\n",
    "        rarible_format = transform_collection_id_for_rarible(orig_id)\n",
    "        if not rarible_format:\n",
    "            print(f\"Skipping invalid format => {orig_id}\")\n",
    "            continue\n",
    "        \n",
    "        data = fetch_rarible_nfts(rarible_format, api_key, size=size)\n",
    "        items = data.get(\"items\", [])\n",
    "        \n",
    "        store_rarible_nfts(db_path, table_nfts, orig_id, items)\n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Inserted up to {len(items)} items for {orig_id}\")\n",
    "    \n",
    "    print(\"Done fetching and storing Rarible NFTs in\", table_nfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/15] Inserted up to 10 items for 0x716ad1b6222046289c1664825cd9e4caf6253aec:match\n",
      "[2/15] Inserted up to 10 items for 0x0c15b61197c8fca4322b8e6c4a744b597622a1dc:base\n",
      "[3/15] Inserted up to 1 items for 0x84f2789475754572311d65173ade3c24e643ba29:base\n",
      "[4/15] Inserted up to 1 items for 0x97683a99e531201de43f68c445a0325a426ebf7c:celo\n",
      "[5/15] Inserted up to 1 items for 0x41ffb8407a23a1c1aa8b948677428e5049b850c1:base\n",
      "[6/15] Inserted up to 1 items for 0x482f1759dd48df2672c0b9a5fc6791b19f4fb7d3:etherlink\n",
      "[7/15] Inserted up to 0 items for 0x7b25869dd5405b82b0debf48642eaca4e2a61a20:abstract\n",
      "[8/15] Inserted up to 1 items for 0xbd88289d94f28cae7a5ea1136be8f78b863bb1cd:base\n",
      "[9/15] Inserted up to 1 items for 0x5f5a2e9642d772a6d9b348621d0330ef0bc4222e:zksync\n",
      "[10/15] Inserted up to 0 items for 0xeeec1bda08cc5a6a26d43406c08d0d35bd54d830:abstract\n",
      "[11/15] Inserted up to 1 items for 0x68de02dab89a266858d74e2ca6707693fff022f16d9d9020f52e08271acade84:aptos\n",
      "[12/15] Inserted up to 1 items for 0x9fcd53e9d106ceb6212f11cd6a20522283c3af53:polygon\n",
      "[13/15] Inserted up to 5 items for 0x64378902d6afb97eb222d3a02cc1c146acfb1c0e:base\n",
      "[14/15] Inserted up to 1 items for 0x594824a3d6e5777b3c7cc202ad1050435aac7698:ethereum\n",
      "[15/15] Inserted up to 1 items for 0x2387084d7ef28b12babc80dca429b267967a33c2:base\n",
      "Done fetching and storing Rarible NFTs in rarible_nfts\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    RARIBLE_API_KEY = \"your_key\"\n",
    "    fetch_rarible_nfts_for_collections(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"rarible_nfts\",\n",
    "        api_key=RARIBLE_API_KEY,\n",
    "        size=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MagicEden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_magiceden_attributes(slug_name):\n",
    "    base_url = \"https://api-mainnet.magiceden.dev/v2/collections\"\n",
    "    url = f\"{base_url}/{slug_name}/attributes\"\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    \n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[MagicEden Attributes] Error {resp.status_code} for slug='{slug_name}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def store_traits_json_for_magiceden(db_path, table_name, slug_name, traits_data):\n",
    "    \"\"\"\n",
    "    Updates the 'sampled_collections' row for marketplace='MagicEden'\n",
    "    and the given slug_name, setting the entire JSON in 'traits_json'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    update_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET traits_json = ?\n",
    "    WHERE marketplace='MagicEden'\n",
    "      AND slug_name=?\n",
    "    \"\"\"\n",
    "    c.execute(update_sql, (json.dumps(traits_data), slug_name))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_and_update_magiceden_traits(db_path=\"random_sample_5.db\", table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    1) Query 'sampled_collections' for rows with marketplace='MagicEden'.\n",
    "    2) For each 'slug_name', call fetch_magiceden_attributes(slug_name).\n",
    "    3) Store the JSON result in 'traits_json' column of the same row.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # We'll fetch all MagicEden slug_names\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='MagicEden'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} Magic Eden collections to update 'traits_json'.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (slug_name,) in rows:\n",
    "        data = fetch_magiceden_attributes(slug_name)\n",
    "        store_traits_json_for_magiceden(db_path, table_name, slug_name, data)\n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Updated 'traits_json' for slug='{slug_name}'\")\n",
    "    \n",
    "    print(\"Done fetching/storing Magic Eden attributes in 'traits_json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 Magic Eden collections to update 'traits_json'.\n",
      "[1/8] Updated 'traits_json' for slug='spotted_lanternflies'\n",
      "[2/8] Updated 'traits_json' for slug='kyoudai_spirits'\n",
      "[3/8] Updated 'traits_json' for slug='solana_mecha_apes'\n",
      "[4/8] Updated 'traits_json' for slug='drip_genopets_s2'\n",
      "[5/8] Updated 'traits_json' for slug='pixelated_apes_dao'\n",
      "[6/8] Updated 'traits_json' for slug='De_Casinos'\n",
      "[7/8] Updated 'traits_json' for slug='moveman'\n",
      "[8/8] Updated 'traits_json' for slug='frostys_friends'\n",
      "Done fetching/storing Magic Eden attributes in 'traits_json'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fetch_and_update_magiceden_traits(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_name=\"sampled_collections\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_magiceden_nfts_table(db_path=\"random_sample_5.db\", table_name=\"magiceden_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table 'magiceden_nfts' with columns for relevant fields from\n",
    "    the Magic Eden listing JSON, plus a link back to 'sampled_collections' via slug_name.\n",
    "    \n",
    "    We'll have 27 columns total:\n",
    "      1) id (PK)\n",
    "      2) collection_slug\n",
    "      ...\n",
    "      26) token_properties_json\n",
    "      27) fetched_at\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Below we define 27 columns total\n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        \n",
    "        collection_slug TEXT,\n",
    "\n",
    "        pdaAddress TEXT,\n",
    "        auctionHouse TEXT,\n",
    "        tokenAddress TEXT,\n",
    "        tokenMint TEXT,\n",
    "        seller TEXT,\n",
    "        sellerReferral TEXT,\n",
    "        tokenSize REAL,\n",
    "        price REAL,\n",
    "        expiry REAL,\n",
    "        \n",
    "        rarity_json TEXT,\n",
    "        extra_json TEXT,\n",
    "        listingSource TEXT,\n",
    "        \n",
    "        token_mintAddress TEXT,\n",
    "        token_owner TEXT,\n",
    "        token_supply REAL,\n",
    "        token_collection TEXT,\n",
    "        token_name TEXT,\n",
    "        token_updateAuthority TEXT,\n",
    "        token_primarySaleHappened INTEGER,\n",
    "        token_sellerFeeBasisPoints REAL,\n",
    "        token_image TEXT,\n",
    "        token_animationUrl TEXT,\n",
    "        token_externalUrl TEXT,\n",
    "        \n",
    "        token_attributes_json TEXT,\n",
    "        token_properties_json TEXT,\n",
    "        \n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_magiceden_listings(collection_slug, limit=10):\n",
    "    \"\"\"\n",
    "    GET https://api-mainnet.magiceden.dev/v2/collections/{collection_slug}/listings?limit={limit}\n",
    "    Returns a list of dicts if successful, else empty list.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api-mainnet.magiceden.dev/v2/collections\"\n",
    "    url = f\"{base_url}/{collection_slug}/listings\"\n",
    "    params = {\"limit\": limit}\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    \n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()  # Should be a list of listing dicts\n",
    "    else:\n",
    "        print(f\"[MagicEden NFT Fetch] Error {resp.status_code} for slug='{collection_slug}': {resp.text}\")\n",
    "        return []\n",
    "\n",
    "def store_magiceden_nfts(db_path, table_name, slug_name, listings):\n",
    "    \"\"\"\n",
    "    Insert each listing item into 'magiceden_nfts'.\n",
    "    We must provide EXACTLY 26 placeholders for these columns (excluding 'id' + including 'fetched_at' as a datetime call).\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # 27 columns total => 'id' is autoincrement, so we have 26 placeholders\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        collection_slug,\n",
    "        \n",
    "        pdaAddress,\n",
    "        auctionHouse,\n",
    "        tokenAddress,\n",
    "        tokenMint,\n",
    "        seller,\n",
    "        sellerReferral,\n",
    "        tokenSize,\n",
    "        price,\n",
    "        expiry,\n",
    "        \n",
    "        rarity_json,\n",
    "        extra_json,\n",
    "        listingSource,\n",
    "        \n",
    "        token_mintAddress,\n",
    "        token_owner,\n",
    "        token_supply,\n",
    "        token_collection,\n",
    "        token_name,\n",
    "        token_updateAuthority,\n",
    "        token_primarySaleHappened,\n",
    "        token_sellerFeeBasisPoints,\n",
    "        token_image,\n",
    "        token_animationUrl,\n",
    "        token_externalUrl,\n",
    "        \n",
    "        token_attributes_json,\n",
    "        token_properties_json,\n",
    "        \n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (\n",
    "        ?,  -- collection_slug\n",
    "        ?,  -- pdaAddress\n",
    "        ?,  -- auctionHouse\n",
    "        ?,  -- tokenAddress\n",
    "        ?,  -- tokenMint\n",
    "        ?,  -- seller\n",
    "        ?,  -- sellerReferral\n",
    "        ?,  -- tokenSize\n",
    "        ?,  -- price\n",
    "        ?,  -- expiry\n",
    "        ?,  -- rarity_json\n",
    "        ?,  -- extra_json\n",
    "        ?,  -- listingSource\n",
    "        ?,  -- token_mintAddress\n",
    "        ?,  -- token_owner\n",
    "        ?,  -- token_supply\n",
    "        ?,  -- token_collection\n",
    "        ?,  -- token_name\n",
    "        ?,  -- token_updateAuthority\n",
    "        ?,  -- token_primarySaleHappened\n",
    "        ?,  -- token_sellerFeeBasisPoints\n",
    "        ?,  -- token_image\n",
    "        ?,  -- token_animationUrl\n",
    "        ?,  -- token_externalUrl\n",
    "        ?,  -- token_attributes_json\n",
    "        ?,  -- token_properties_json\n",
    "        datetime('now')  -- fetched_at\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Notice we have exactly 26 placeholders (the last column uses datetime('now')).\n",
    "\n",
    "    for listing in listings:\n",
    "        pdaAddress = listing.get(\"pdaAddress\", \"\")\n",
    "        auctionHouse = listing.get(\"auctionHouse\", \"\")\n",
    "        tokenAddress = listing.get(\"tokenAddress\", \"\")\n",
    "        tokenMint = listing.get(\"tokenMint\", \"\")\n",
    "        seller = listing.get(\"seller\", \"\")\n",
    "        sellerReferral = listing.get(\"sellerReferral\", \"\")\n",
    "        tokenSize = listing.get(\"tokenSize\", 0)\n",
    "        price = listing.get(\"price\", 0)\n",
    "        expiry = listing.get(\"expiry\", 0)\n",
    "        \n",
    "        # Convert 'rarity' and 'extra' to JSON strings\n",
    "        rarity_json = json.dumps(listing.get(\"rarity\", {}))\n",
    "        extra_json = json.dumps(listing.get(\"extra\", {}))\n",
    "        \n",
    "        listingSource = listing.get(\"listingSource\", \"\")\n",
    "        \n",
    "        token_obj = listing.get(\"token\", {})\n",
    "        token_mintAddress = token_obj.get(\"mintAddress\", \"\")\n",
    "        token_owner = token_obj.get(\"owner\", \"\")\n",
    "        token_supply = token_obj.get(\"supply\", 0)\n",
    "        token_collection = token_obj.get(\"collection\", \"\")\n",
    "        token_name = token_obj.get(\"name\", \"\")\n",
    "        token_updateAuthority = token_obj.get(\"updateAuthority\", \"\")\n",
    "        \n",
    "        primarySaleHappened = 1 if token_obj.get(\"primarySaleHappened\", False) else 0\n",
    "        sellerFeeBasisPoints = token_obj.get(\"sellerFeeBasisPoints\", 0)\n",
    "        token_image = token_obj.get(\"image\", \"\")\n",
    "        token_animationUrl = token_obj.get(\"animationUrl\", \"\")\n",
    "        token_externalUrl = token_obj.get(\"externalUrl\", \"\")\n",
    "        \n",
    "        attributes_json = json.dumps(token_obj.get(\"attributes\", []))\n",
    "        properties_json = json.dumps(token_obj.get(\"properties\", {}))\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            slug_name,\n",
    "            pdaAddress,\n",
    "            auctionHouse,\n",
    "            tokenAddress,\n",
    "            tokenMint,\n",
    "            seller,\n",
    "            sellerReferral,\n",
    "            tokenSize,\n",
    "            price,\n",
    "            expiry,\n",
    "            rarity_json,\n",
    "            extra_json,\n",
    "            listingSource,\n",
    "            token_mintAddress,\n",
    "            token_owner,\n",
    "            token_supply,\n",
    "            token_collection,\n",
    "            token_name,\n",
    "            token_updateAuthority,\n",
    "            primarySaleHappened,\n",
    "            sellerFeeBasisPoints,\n",
    "            token_image,\n",
    "            token_animationUrl,\n",
    "            token_externalUrl,\n",
    "            attributes_json,\n",
    "            properties_json\n",
    "            # fetched_at => datetime('now') in SQL\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_magiceden_nfts_for_collections(db_path=\"random_sample_5.db\",\n",
    "                                         table_collections=\"sampled_collections\",\n",
    "                                         table_nfts=\"magiceden_nfts\",\n",
    "                                         limit=10):\n",
    "    \"\"\"\n",
    "    Creates table if necessary, then for each row with marketplace='MagicEden',\n",
    "    uses 'slug_name' to fetch up to {limit} items from Magic Eden,\n",
    "    storing them in magiceden_nfts.\n",
    "    \"\"\"\n",
    "    create_magiceden_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='MagicEden'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    count = 0\n",
    "    for (slug_name,) in rows:\n",
    "        data = fetch_magiceden_listings(slug_name, limit=limit)\n",
    "        store_magiceden_nfts(db_path, table_nfts, slug_name, data)\n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Inserted up to {len(data)} items for MagicEden => {slug_name}\")\n",
    "    \n",
    "    print(f\"Done fetching/storing MagicEden listings in {table_nfts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/8] Inserted up to 7 items for MagicEden => spotted_lanternflies\n",
      "[2/8] Inserted up to 10 items for MagicEden => kyoudai_spirits\n",
      "[3/8] Inserted up to 10 items for MagicEden => solana_mecha_apes\n",
      "[4/8] Inserted up to 10 items for MagicEden => drip_genopets_s2\n",
      "[5/8] Inserted up to 0 items for MagicEden => pixelated_apes_dao\n",
      "[6/8] Inserted up to 10 items for MagicEden => De_Casinos\n",
      "[7/8] Inserted up to 10 items for MagicEden => moveman\n",
      "[8/8] Inserted up to 10 items for MagicEden => frostys_friends\n",
      "Done fetching/storing MagicEden listings in magiceden_nfts\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fetch_magiceden_nfts_for_collections(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"magiceden_nfts\",\n",
    "        limit=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_atomic_collection_stats(collection_name):\n",
    "    \"\"\"\n",
    "    Calls /atomicassets/v1/collections/{collection_name}/stats\"\n",
    "    \"\"\"\n",
    "    url = f\"https://wax.api.atomicassets.io/atomicassets/v1/collections/{collection_name}/stats\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[Atomic Stats] Error {resp.status_code} for collection='{collection_name}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def update_atomic_collection_total_supply(db_path=\"random_sample_5.db\",\n",
    "                                          table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    1) Query 'sampled_collections' where marketplace='Atomic',\n",
    "       using 'slug_name' as the collection_name.\n",
    "    2) For each row, call fetch_atomic_collection_stats(...),\n",
    "       parse data[\"data\"][\"assets\"], and store it in 'total_supply'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='Atomic'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} 'Atomic' collections to update total_supply.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (collection_name,) in rows:\n",
    "        stats_data = fetch_atomic_collection_stats(collection_name)\n",
    "        # stats_data => { \"success\": bool, \"data\": {...}, ... }\n",
    "        if not stats_data.get(\"success\", False):\n",
    "            print(f\"Skipping {collection_name}, 'success' is False or missing.\")\n",
    "            continue\n",
    "        \n",
    "        # If \"assets\" is None or missing, default to \"0\"\n",
    "        assets_str = stats_data.get(\"data\", {}).get(\"assets\")\n",
    "        if assets_str is None:\n",
    "            assets_str = \"0\"\n",
    "        \n",
    "        try:\n",
    "            assets_count = int(assets_str)\n",
    "        except ValueError:\n",
    "            assets_count = 0  # or handle differently if needed\n",
    "        \n",
    "        conn2 = sqlite3.connect(db_path)\n",
    "        c2 = conn2.cursor()\n",
    "        update_stmt = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET total_supply = ?\n",
    "        WHERE marketplace='Atomic'\n",
    "          AND slug_name=?\n",
    "        \"\"\"\n",
    "        c2.execute(update_stmt, (assets_count, collection_name))\n",
    "        conn2.commit()\n",
    "        conn2.close()\n",
    "        \n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Updated total_supply={assets_count} for {collection_name}\")\n",
    "    \n",
    "    print(\"Done updating total_supply for Atomic collections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 'Atomic' collections to update total_supply.\n",
      "[1/3] Updated total_supply=10 for nftartdesing\n",
      "[2/3] Updated total_supply=20 for targetedby11\n",
      "[3/3] Updated total_supply=5 for alienwor1dsz\n",
      "Done updating total_supply for Atomic collections.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    update_atomic_collection_total_supply(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_name=\"sampled_collections\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_atomic_nfts_table(db_path=\"random_sample_5.db\", table_name=\"atomic_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table that stores item-level data from the AtomicAssets API.\n",
    "    Adjust columns as needed to match your chosen fields.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        \n",
    "        -- references the original 'collection_name' from 'sampled_collections' (Atomic)\n",
    "        collection_name TEXT,\n",
    "        \n",
    "        asset_id TEXT,\n",
    "        owner TEXT,\n",
    "        item_name TEXT,\n",
    "        is_transferable INTEGER,\n",
    "        is_burnable INTEGER,\n",
    "        \n",
    "        template_id TEXT,        -- from template[\"template_id\"]\n",
    "        max_supply TEXT,         -- from template[\"max_supply\"]\n",
    "        issued_supply TEXT,      -- from template[\"issued_supply\"]\n",
    "        \n",
    "        minted_at_time TEXT,     -- item[\"minted_at_time\"]\n",
    "        minted_at_block TEXT,    -- item[\"minted_at_block\"]\n",
    "        \n",
    "        data_json TEXT,          -- optionally store the entire item if you like\n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_atomic_assets(collection_name, limit=10):\n",
    "    \"\"\"\n",
    "    Calls the endpoint:\n",
    "      GET /atomicassets/v1/assets?collection_name={collection_name}&limit={limit}\n",
    "    Returns a dict with \"success\", \"data\" (list), and \"query_time\".\n",
    "    We'll return the entire JSON for reference.\n",
    "    \"\"\"\n",
    "    base_url = \"https://wax.api.atomicassets.io/atomicassets/v1/assets\"\n",
    "    params = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    resp = requests.get(base_url, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()  # e.g. { \"success\": true, \"data\": [...], \"query_time\": 0 }\n",
    "    else:\n",
    "        print(f\"[Atomic NFT Fetch] Error {resp.status_code} => {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def store_atomic_nfts(db_path, table_name, coll_name, items):\n",
    "    \"\"\"\n",
    "    Inserts the provided item-level data into 'atomic_nfts'.\n",
    "    items is a list of dicts from data[\"data\"] in the AtomicAssets response.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        collection_name,\n",
    "        asset_id,\n",
    "        owner,\n",
    "        item_name,\n",
    "        is_transferable,\n",
    "        is_burnable,\n",
    "        template_id,\n",
    "        max_supply,\n",
    "        issued_supply,\n",
    "        minted_at_time,\n",
    "        minted_at_block,\n",
    "        data_json,\n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in items:\n",
    "        asset_id = item.get(\"asset_id\", \"\")\n",
    "        owner = item.get(\"owner\", \"\")\n",
    "        item_name = item.get(\"name\", \"\")\n",
    "        \n",
    "        # Convert booleans to int\n",
    "        is_transferable = 1 if item.get(\"is_transferable\", False) else 0\n",
    "        is_burnable = 1 if item.get(\"is_burnable\", False) else 0\n",
    "        \n",
    "        # Safely handle template, which can be None\n",
    "        template = item.get(\"template\") or {}\n",
    "        template_id = template.get(\"template_id\", \"\")\n",
    "        max_supply = template.get(\"max_supply\", \"\")\n",
    "        issued_supply = template.get(\"issued_supply\", \"\")\n",
    "        \n",
    "        minted_at_time = item.get(\"minted_at_time\", \"\")\n",
    "        minted_at_block = item.get(\"minted_at_block\", \"\")\n",
    "        \n",
    "        data_json = json.dumps(item)\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            coll_name,\n",
    "            asset_id,\n",
    "            owner,\n",
    "            item_name,\n",
    "            is_transferable,\n",
    "            is_burnable,\n",
    "            template_id,\n",
    "            max_supply,\n",
    "            issued_supply,\n",
    "            minted_at_time,\n",
    "            minted_at_block,\n",
    "            data_json\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "def fetch_atomic_nfts_for_collections(db_path=\"random_sample_5.db\",\n",
    "                                      table_collections=\"sampled_collections\",\n",
    "                                      table_nfts=\"atomic_nfts\",\n",
    "                                      limit=10):\n",
    "    \"\"\"\n",
    "    1) Create the 'atomic_nfts' table if not exists.\n",
    "    2) Query 'sampled_collections' for marketplace='Atomic'.\n",
    "       We'll assume there's a column 'collection_name' for each row.\n",
    "    3) For each row, call fetch_atomic_assets(collection_name, limit={limit}),\n",
    "       then store them in 'atomic_nfts'.\n",
    "    \"\"\"\n",
    "    # 1) create table\n",
    "    create_atomic_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    # 2) get the relevant rows from 'sampled_collections'\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='Atomic'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} Atomic collections to fetch up to {limit} assets each.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (coll_name,) in rows:\n",
    "        print(f\"[{count+1}/{len(rows)}] Fetching {limit} assets for collection_name='{coll_name}'\")\n",
    "        \n",
    "        data = fetch_atomic_assets(coll_name, limit=limit)\n",
    "        items = data.get(\"data\", [])  # a list of item dicts\n",
    "        \n",
    "        store_atomic_nfts(db_path, table_nfts, coll_name, items)\n",
    "        count += 1\n",
    "    \n",
    "    print(\"Done fetching/storing Atomic NFTs in\", table_nfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 Atomic collections to fetch up to 10 assets each.\n",
      "[1/3] Fetching 10 assets for collection_name='nftartdesing'\n",
      "[2/3] Fetching 10 assets for collection_name='targetedby11'\n",
      "[3/3] Fetching 10 assets for collection_name='alienwor1dsz'\n",
      "Done fetching/storing Atomic NFTs in atomic_nfts\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fetch_atomic_nfts_for_collections(\n",
    "        db_path=\"random_sample_5.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"atomic_nfts\",\n",
    "        limit=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
