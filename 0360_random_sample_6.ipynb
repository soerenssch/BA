{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import sqlite3\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Randomized Sample 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sixth_random_sample():\n",
    "    source_db = \"sampling_frame.db\"\n",
    "    sample1_db = \"random_sample_1.db\"\n",
    "    sample2_db = \"random_sample_2.db\"\n",
    "    sample3_db = \"random_sample_3.db\"\n",
    "    sample4_db = \"random_sample_4.db\"\n",
    "    sample5_db = \"random_sample_5.db\"\n",
    "    sixth_sample_db = \"random_sample_6.db\"\n",
    "    table_name = \"sampled_collections\"\n",
    "    sample_size = 45 \n",
    "    \n",
    "    # Load full dataset\n",
    "    conn_source = sqlite3.connect(source_db)\n",
    "    df_full = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn_source)\n",
    "    conn_source.close()\n",
    "\n",
    "    # Load previous samples\n",
    "    conn1 = sqlite3.connect(sample1_db)\n",
    "    df1 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn1)\n",
    "    conn1.close()\n",
    "\n",
    "    conn2 = sqlite3.connect(sample2_db)\n",
    "    df2 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn2)\n",
    "    conn2.close()\n",
    "\n",
    "    conn3 = sqlite3.connect(sample3_db)\n",
    "    df3 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn3)\n",
    "    conn3.close()\n",
    "\n",
    "    conn4 = sqlite3.connect(sample4_db)\n",
    "    df4 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn4)\n",
    "    conn4.close()    \n",
    "\n",
    "    conn5 = sqlite3.connect(sample5_db)\n",
    "    df5 = pd.read_sql_query(f\"SELECT * FROM {table_name}\", conn5)\n",
    "    conn5.close()     \n",
    "\n",
    "    # Check for required column\n",
    "    if \"slug_name\" not in df_full.columns:\n",
    "        raise ValueError(\"Missing 'slug_name' column in source data.\")\n",
    "\n",
    "    # Exclude all previously sampled collection_ids\n",
    "    previously_sampled_ids = set(df1[\"slug_name\"]).union(df2[\"slug_name\"], df3[\"slug_name\"], df4[\"slug_name\"], df5[\"slug_name\"])\n",
    "    df_remaining = df_full[~df_full[\"slug_name\"].isin(previously_sampled_ids)]\n",
    "\n",
    "    print(f\"Remaining collections after excluding first 5 samples: {len(df_remaining)}\")\n",
    "\n",
    "    # Draw the fourth sample\n",
    "    df_sixth_sample = df_remaining.sample(n=sample_size, random_state=789)\n",
    "    print(f\"Sampled {len(df_sixth_sample)} collections for fifth sample.\")\n",
    "\n",
    "    # Write to new database\n",
    "    conn_fifth = sqlite3.connect(sixth_sample_db)\n",
    "    df_sixth_sample.to_sql(table_name, conn_fifth, if_exists=\"replace\", index=False)\n",
    "    conn_fifth.close()\n",
    "\n",
    "    print(f\"Sixth sample saved to '{df_sixth_sample}' in table '{table_name}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining collections after excluding first 5 samples: 47\n",
      "Sampled 45 collections for fifth sample.\n",
      "Sixth sample saved to '          id                                      collection_id marketplace  \\\n",
      "143  5419073                                               None   MagicEden   \n",
      "12   4397835   0x84498198d1d34497b8ff90562ccc178d2f812d87:matic     OpenSea   \n",
      "37   4825276   0xfb0262863ad07954b1dcbc7855a6ab8c3b93efc1:matic     OpenSea   \n",
      "71    431707    0x3319197b0d0f8ccd1087f2d2e47a8fb7c0710171:base     OpenSea   \n",
      "116    44478    0xf3e599db00a9a41785b619cbc87c86019349dda5:lisk     Rarible   \n",
      "51   3447426  0x436119dafa0e5160aa17e310da858ccfeb937c4e:eth...     Rarible   \n",
      "203  4065612    0x38aebd5ad1b71374cc59f5f1271c29e3cfb62caa:rari     Rarible   \n",
      "184  5530618                                               None      Atomic   \n",
      "153  5408304  0x7a420aeff902aaa2c85a190d7b91ce8beffffe14:ava...     OpenSea   \n",
      "4    5344167    0x78cff43be0978f5f832efc84a90e201a52017fd7:zora     OpenSea   \n",
      "98   4436205  0x0185e67152ef0538f73db4db940d633c4dbc9342:arb...     OpenSea   \n",
      "192  5518512                                               None      Atomic   \n",
      "111   514582   0xbefc6b1ac05ecff75f8f1866d801e990d01dc0bd:telos     Rarible   \n",
      "115  4322133  0x4d0ebfea0d8c49a1a7514b39ca02d7d01a49f36a:son...     OpenSea   \n",
      "191  5510550                                               None      Atomic   \n",
      "61   4338818    0xc79fcfa5895f14f336e5486dbd363c54f750f095:flow     OpenSea   \n",
      "58   3394790   0x4e042f1d2f24ad0794a24a7a42d58b7c73f766af:kroma     Rarible   \n",
      "204  3394459   0xb7be41cfb1eb2f15c16e144ba2e90eb8828749ab:kroma     Rarible   \n",
      "159  3862449    0x471c250781cd7a64ab37f227e9ceee956cc9ca7a:base     Rarible   \n",
      "34   5414713                                               None   MagicEden   \n",
      "230   486168  0x193ba2c46519459ad536ea580978faffef575ba7:pol...     Rarible   \n",
      "35    530909    0x55b1316d3065f4f88733d0aed9632a5ab8906ebd:base     Rarible   \n",
      "162   873032    0x735d8a60455acf37a617e241163e2d593b9eb439:base     Rarible   \n",
      "134  5436258                                               None   MagicEden   \n",
      "144  5433190                                               None   MagicEden   \n",
      "15   4293401    0xa60d25648d3f6d3ba7883eccab253b35312578b6:flow     OpenSea   \n",
      "155  5417711                                               None   MagicEden   \n",
      "135  5433006                                               None   MagicEden   \n",
      "148  5433661                                               None   MagicEden   \n",
      "19   5036671   0x100bb47f66cace58d9a46dc0a3fa57dacd5f281a:blast     OpenSea   \n",
      "74   5397070   0x5bcf39550d8d8b2fb53a7a57d7df654fb4db541e:matic     OpenSea   \n",
      "124  5436062                                               None   MagicEden   \n",
      "123  5428542                                               None   MagicEden   \n",
      "199  4467568  0x9443781158a29ea6aee613dfcf5c776f129755e6:ava...     OpenSea   \n",
      "145  5420478                                               None   MagicEden   \n",
      "79   3215862  0xe6d1b14467afaf1dab6cab4c484b67da214937e8:imm...     Rarible   \n",
      "49   3519285    0x6aeb5e6f18826f33debd54bfac55dae3bfa677dd:celo     Rarible   \n",
      "88   5378358    0x1fc14823135f2f3f8c17aa3131b706714ab4efa2:zora     OpenSea   \n",
      "133  4996760  0xfd5b805bdf5f331f89ccf124a039959f14908792:opt...     OpenSea   \n",
      "101  5435590                                               None   MagicEden   \n",
      "151    89871    0x1a5de3bac5917a806cdaaac29a4391e517794ce5:base     Rarible   \n",
      "126  5425984                                               None   MagicEden   \n",
      "66   4778120   0xc0e536b3069e901eac473047424217855b9fa365:matic     OpenSea   \n",
      "5    5003111   0xfe68cddace1f4ac6f1fe77db35722a336b0177e9:matic     OpenSea   \n",
      "92   5409914                                               None   MagicEden   \n",
      "\n",
      "                                             slug_name  \\\n",
      "143                                       titan_whales   \n",
      "12           lens-collect-profile-199929-publication-3   \n",
      "37   municipios-del-futuro-cluster-de-iot-de-la-com...   \n",
      "71                                               hypio   \n",
      "116                                           web3talk   \n",
      "51                                      Hawk Tuah 2024   \n",
      "203                                        Fingerprint   \n",
      "184                                       oddsandendss   \n",
      "153                                 dragon-crypto-hero   \n",
      "4                                       summer-vibe-10   \n",
      "98                                      family-edition   \n",
      "192                                       cardinallind   \n",
      "111                                           Concepts   \n",
      "115                                              xlfrw   \n",
      "191                                       dreamhunters   \n",
      "61                                        sudocat-flow   \n",
      "58                                                 zaz   \n",
      "204                                         Black Lady   \n",
      "159                                             Micro3   \n",
      "34                                               yetiz   \n",
      "230  Lens Collect | Profile #138830 - Publication #375   \n",
      "35                                          xiandandan   \n",
      "162                    Arielle Barajas-Melton - Member   \n",
      "134                                         heavenland   \n",
      "144                                       the_frontier   \n",
      "15                                  glow-panda-genesis   \n",
      "155                                         cyberspies   \n",
      "135                                        coast2coast   \n",
      "148                                metavillagemansions   \n",
      "19                                   delfin-ohno-blast   \n",
      "74                              dancing-girls-in-color   \n",
      "124                             neon_clouds_collective   \n",
      "123                                       oak_paradise   \n",
      "199                                         personas-3   \n",
      "145                                      skatex_events   \n",
      "79                                    Zombie Squirrels   \n",
      "49       Response 430b1462-f17f-418c-ba61-93bf70f30b3f   \n",
      "88                                           zora-1531   \n",
      "133                                         how-to-pod   \n",
      "101                                 cool_penguin_squad   \n",
      "151                                              iahoo   \n",
      "126                                           mrclpass   \n",
      "66                 open-ticketing-ecosystem-event-8355   \n",
      "5                                 stained-glasswindows   \n",
      "92                                            pawspaws   \n",
      "\n",
      "                                             full_name  \\\n",
      "143                                       Titan Whales   \n",
      "12     Lens Collect | Profile #199929 - Publication #3   \n",
      "37   Municipios del Futuro - Cluster de IoT de la C...   \n",
      "71                                Wealthy Hypio Babies   \n",
      "116                                           web3talk   \n",
      "51                                      Hawk Tuah 2024   \n",
      "203                                           Untitled   \n",
      "184                            Little of this and that   \n",
      "153                                 Dragon Crypto Hero   \n",
      "4                                          summer vibe   \n",
      "98                                      Family edition   \n",
      "192                                       cardinallind   \n",
      "111                                           Untitled   \n",
      "115                                              xlfrw   \n",
      "191                                      Dream Hunters   \n",
      "61                                             SudoCat   \n",
      "58                                                 zaz   \n",
      "204                                         Black Lady   \n",
      "159                                             Micro3   \n",
      "34                                               Yetiz   \n",
      "230  Lens Collect | Profile #138830 - Publication #375   \n",
      "35                                            Untitled   \n",
      "162                                           Untitled   \n",
      "134                                         Heavenland   \n",
      "144                                       The Frontier   \n",
      "15                                  GLOW PANDA GENESIS   \n",
      "155                                        Cyber Spies   \n",
      "135                                 SkateX Coast2Coast   \n",
      "148                               Metavillage Mansions   \n",
      "19                                   DELFIN OHNO BLAST   \n",
      "74                              Dancing Girls in color   \n",
      "124                             Neon Clouds Collective   \n",
      "123                                       Oak Paradise   \n",
      "199                                           Personas   \n",
      "145                                SkateX Event Series   \n",
      "79                                    Zombie Squirrels   \n",
      "49                                            Untitled   \n",
      "88                                                Zora   \n",
      "133                                        How to Pod.   \n",
      "101                                 Cool Penguin Squad   \n",
      "151                                           Untitled   \n",
      "126                                 Miracle World Pass   \n",
      "66                 Open Ticketing Ecosystem Event 8355   \n",
      "5                                Stained Glass Windows   \n",
      "92                                            PawsPaws   \n",
      "\n",
      "                                           description  \\\n",
      "143  999 Titan Whales are coming to Solana Web3 to ...   \n",
      "12                                                       \n",
      "37   Este certificado es un NFT (Token No Fungible)...   \n",
      "71   Wealthy Hypio Babies are a cultural virus born...   \n",
      "116            here we dicuss what is going on in web3   \n",
      "51                                                       \n",
      "203                                                      \n",
      "184                                                      \n",
      "153  An NFT avatar is required to play The Legend o...   \n",
      "4                                                        \n",
      "98                                                       \n",
      "192                                                      \n",
      "111                                                      \n",
      "115                                                      \n",
      "191                                                      \n",
      "61                                                       \n",
      "58                                                 zaz   \n",
      "204                                                      \n",
      "159  Unlock your Airdrop with Micro3 Citizen\\n\\nBec...   \n",
      "34   Yetiz aren't just mighty mountain creatures; t...   \n",
      "230                                                      \n",
      "35                                                       \n",
      "162                                                      \n",
      "134  Heaven Land builds a virtual reality platform ...   \n",
      "144  The Frontier is a unique Western Hotel & Saloo...   \n",
      "15                                                       \n",
      "155  312 Cyber Spies Operating on the Solana Blockc...   \n",
      "135  SkateX Coast2Coast is a one of a kind collecti...   \n",
      "148  The social building blocks for a metaverse wor...   \n",
      "19                                                       \n",
      "74   \"Dancing Girls in Color\" presents an electrify...   \n",
      "124  The Neon Clouds Collective is a deflationary, ...   \n",
      "123  Oak Paradise is building sportsbook, casino an...   \n",
      "199                                                      \n",
      "145  SkateX Event Series are limited NFTs awarded t...   \n",
      "79   2,500 Zombie Squirrels have risen from the dea...   \n",
      "49                                                       \n",
      "88                                                       \n",
      "133  https://mirror.xyz/10/0xfd5b805bdf5f331f89ccf1...   \n",
      "101  4,444 brawling penguins engaged in Penguin War...   \n",
      "151                                                      \n",
      "126  1222 humanoids are ready to work for you and b...   \n",
      "66                                                       \n",
      "5    **Stained Glass-Windows Collection** are new d...   \n",
      "92   A group of brave animal, they have hi IQ, live...   \n",
      "\n",
      "                         category token_standard   created_time  \\\n",
      "143               [\"pfps\", \"art\"]                                 \n",
      "12                                                                \n",
      "37                    memberships                                 \n",
      "71                   unclassified                    09/01/2025   \n",
      "116                                      ERC1155                  \n",
      "51                   domain-names         ERC721                  \n",
      "203                                       ERC721                  \n",
      "184                                               1618941939000   \n",
      "153                  unclassified                    16/08/2022   \n",
      "4                                                                 \n",
      "98                                                                \n",
      "192                                               1623773616500   \n",
      "111                                       ERC721                  \n",
      "115                                                               \n",
      "191                                               1632242352500   \n",
      "61                    memberships                                 \n",
      "58                                        ERC721                  \n",
      "204                                      ERC1155                  \n",
      "159                                       ERC721                  \n",
      "34              [\"games\", \"pfps\"]                                 \n",
      "230                                       ERC721                  \n",
      "35                   domain-names         ERC721                  \n",
      "162                                       ERC721                  \n",
      "134                 [\"launchpad\"]                                 \n",
      "144                [\"pfp\", \"art\"]                                 \n",
      "15                                                                \n",
      "155             [\"pfps\", \"games\"]                                 \n",
      "135  [\"virtual_worlds\", \"sports\"]                                 \n",
      "148            [\"virtual_worlds\"]                                 \n",
      "19                                                                \n",
      "74                    photography                                 \n",
      "124                       [\"pfp\"]                                 \n",
      "123                       [\"pfp\"]                                 \n",
      "199                                                               \n",
      "145           [\"games\", \"sports\"]                                 \n",
      "79                                        ERC721                  \n",
      "49                                        ERC721                  \n",
      "88                                                                \n",
      "133                                                               \n",
      "101             [\"pfps\", \"games\"]                                 \n",
      "151                                       ERC721                  \n",
      "126   [\"games\", \"virtual_worlds\"]                                 \n",
      "66                                                                \n",
      "5                             art                                 \n",
      "92                       [\"pfps\"]                                 \n",
      "\n",
      "                                             image_url  ... instagram_url  \\\n",
      "143  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "12                                                      ...                 \n",
      "37   https://i.seadn.io/s/raw/files/6dc097e92ca75c4...  ...                 \n",
      "71                                                      ...          None   \n",
      "116                                                     ...                 \n",
      "51   https://i.seadn.io/s/raw/files/ee0cc2859942dff...  ...                 \n",
      "203                                                     ...                 \n",
      "184                                                     ...          None   \n",
      "153                                                     ...          None   \n",
      "4    https://i.seadn.io/s/raw/files/a40097652b50053...  ...                 \n",
      "98   https://i.seadn.io/s/raw/files/f8997edbc0183b4...  ...                 \n",
      "192                                                     ...          None   \n",
      "111                                                     ...                 \n",
      "115                                                     ...                 \n",
      "191                                                     ...          None   \n",
      "61   https://i.seadn.io/s/raw/files/95694d150131da2...  ...                 \n",
      "58                                                      ...                 \n",
      "204                                                     ...                 \n",
      "159  https://i.seadn.io/s/raw/files/daf2d267ad6e2b4...  ...                 \n",
      "34   https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "230                                                     ...                 \n",
      "35   https://i.seadn.io/s/raw/files/9692498b8063c78...  ...                 \n",
      "162                                                     ...                 \n",
      "134  https://bafybeibaj7dpvpfml3i2ktr2gv2ujynyo2eah...  ...                 \n",
      "144  https://bafybeihwhuhbwly65bpry22um4xwpyetog4lf...  ...                 \n",
      "15   https://i.seadn.io/s/raw/files/c78cdb7d6ed8e1f...  ...                 \n",
      "155  https://gateway.pinit.io/ipfs/QmbfPT4t9T4XVRn4...  ...                 \n",
      "135  https://bafybeiawbaogqp6xlrkth3duo3czt4ojf5ljq...  ...                 \n",
      "148  https://pbs.twimg.com/profile_images/150506510...  ...                 \n",
      "19   https://i.seadn.io/s/raw/files/6541435d2dc3f36...  ...                 \n",
      "74   https://i.seadn.io/s/raw/files/8339b7ec6c3c099...  ...                 \n",
      "124  https://arweave.net/rELsxMyfGIuGMpmA5x0JBoCZtb...  ...                 \n",
      "123  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "199  https://i.seadn.io/s/raw/files/8ed7c56ba557f6d...  ...                 \n",
      "145  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "79                                                      ...                 \n",
      "49                                                      ...                 \n",
      "88   https://i.seadn.io/s/raw/files/c3725b1ba998d49...  ...                 \n",
      "133  https://i.seadn.io/s/raw/files/ac37a6652cc3e26...  ...                 \n",
      "101  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "151                                                     ...                 \n",
      "126  https://creator-hub-prod.s3.us-east-2.amazonaw...  ...                 \n",
      "66   https://i.seadn.io/s/raw/files/ad4b567b5e819f5...  ...                 \n",
      "5    https://i.seadn.io/s/raw/files/f8ddd7754563b98...  ...     holgers47   \n",
      "92   https://arweave.net/7TLyFdrTyDVk9bBgi_9jkOLvRX...  ...                 \n",
      "\n",
      "    facebook_url                         discord_url telegram_url  \\\n",
      "143               https://www.discord.gg/titanwhales                \n",
      "12                                                                  \n",
      "37                                                                  \n",
      "71                                              None         None   \n",
      "116                                                                 \n",
      "51                                                                  \n",
      "203                                                                 \n",
      "184         None                                None         None   \n",
      "153                                             None         None   \n",
      "4                                                                   \n",
      "98                                                                  \n",
      "192         None                                None         None   \n",
      "111                                                                 \n",
      "115                                                                 \n",
      "191         None                                None         None   \n",
      "61                                                                  \n",
      "58                                                                  \n",
      "204                                                                 \n",
      "159                                                                 \n",
      "34                      https://www.discord.gg/pixiz                \n",
      "230                                                                 \n",
      "35                                                                  \n",
      "162                                                                 \n",
      "134                                                                 \n",
      "144                                                                 \n",
      "15                                                                  \n",
      "155                                                                 \n",
      "135                                                                 \n",
      "148                          https://t.co/rq760CiFC9                \n",
      "19                                                                  \n",
      "74                                                                  \n",
      "124                                                                 \n",
      "123                                                                 \n",
      "199                                                                 \n",
      "145                    https://www.discord.gg/skatex                \n",
      "79                                                                  \n",
      "49                                                                  \n",
      "88                                                                  \n",
      "133                                                                 \n",
      "101                https://www.discord.gg/eAMGR6VUfv                \n",
      "151                                                                 \n",
      "126                  https://www.discord.gg/bQ543qur                \n",
      "66                                                                  \n",
      "5                                                                   \n",
      "92                                                                  \n",
      "\n",
      "    marketplace_fee royalty_fee  marketplace_stratum  blockchain_stratum  \\\n",
      "143             NaN         NaN                 None                None   \n",
      "12              NaN         NaN              OpenSea                None   \n",
      "37              NaN         NaN                 None                None   \n",
      "71             2.50         3.0                 None                None   \n",
      "116             NaN         NaN                 None                lisk   \n",
      "51              NaN         NaN                 None                None   \n",
      "203             NaN         NaN                 None                rari   \n",
      "184            0.15         NaN               Atomic                None   \n",
      "153            2.50         6.0                 None                None   \n",
      "4               NaN         NaN              OpenSea                None   \n",
      "98              NaN         NaN                 None       arbitrum_nova   \n",
      "192            0.05         NaN               Atomic                None   \n",
      "111             NaN         NaN                 None               telos   \n",
      "115             NaN         NaN                 None             soneium   \n",
      "191            0.05         NaN               Atomic                None   \n",
      "61              NaN         NaN                 None                flow   \n",
      "58              NaN         NaN                 None               kroma   \n",
      "204             NaN         NaN                 None               kroma   \n",
      "159             NaN         NaN                 None                None   \n",
      "34              NaN         NaN            MagicEden                None   \n",
      "230             NaN         NaN                 None                None   \n",
      "35              NaN         NaN                 None                None   \n",
      "162             NaN         NaN                 None                None   \n",
      "134             NaN         NaN                 None                None   \n",
      "144             NaN         NaN                 None                None   \n",
      "15              NaN         NaN                 None                flow   \n",
      "155             NaN         NaN                 None                None   \n",
      "135             NaN         NaN                 None                None   \n",
      "148             NaN         NaN                 None                None   \n",
      "19              NaN         NaN                 None               blast   \n",
      "74              NaN         NaN                 None                None   \n",
      "124             NaN         NaN                 None                None   \n",
      "123             NaN         NaN                 None                None   \n",
      "199             NaN         NaN                 None           avalanche   \n",
      "145             NaN         NaN                 None                None   \n",
      "79              NaN         NaN                 None          immutablex   \n",
      "49              NaN         NaN              Rarible                None   \n",
      "88              NaN         NaN              OpenSea                None   \n",
      "133             NaN         NaN                 None            optimism   \n",
      "101             NaN         NaN            MagicEden                None   \n",
      "151             NaN         NaN                 None                base   \n",
      "126             NaN         NaN            MagicEden                None   \n",
      "66              NaN         NaN              OpenSea                None   \n",
      "5               NaN         NaN                 None                None   \n",
      "92              NaN         NaN            MagicEden                None   \n",
      "\n",
      "    category_stratum token_standard_stratum  \n",
      "143             pfps                   None  \n",
      "12              None                   None  \n",
      "37       memberships                   None  \n",
      "71      unclassified                   None  \n",
      "116             None                   None  \n",
      "51      domain-names                   None  \n",
      "203             None                   None  \n",
      "184             None                   None  \n",
      "153     unclassified                   None  \n",
      "4               None                   None  \n",
      "98              None                   None  \n",
      "192             None                   None  \n",
      "111             None                   None  \n",
      "115             None                   None  \n",
      "191             None                   None  \n",
      "61              None                   None  \n",
      "58              None                   None  \n",
      "204             None                   None  \n",
      "159             None                 erc721  \n",
      "34              None                   None  \n",
      "230             None                 erc721  \n",
      "35      domain-names                   None  \n",
      "162             None                 erc721  \n",
      "134        launchpad                   None  \n",
      "144              pfp                   None  \n",
      "15              None                   None  \n",
      "155            games                   None  \n",
      "135           sports                   None  \n",
      "148   virtual_worlds                   None  \n",
      "19              None                   None  \n",
      "74       photography                   None  \n",
      "124              pfp                   None  \n",
      "123              pfp                   None  \n",
      "199             None                   None  \n",
      "145           sports                   None  \n",
      "79              None                   None  \n",
      "49              None                   None  \n",
      "88              None                   None  \n",
      "133             None                   None  \n",
      "101             None                   None  \n",
      "151             None                   None  \n",
      "126             None                   None  \n",
      "66              None                   None  \n",
      "5                art                   None  \n",
      "92              None                   None  \n",
      "\n",
      "[45 rows x 22 columns]' in table 'sampled_collections'.\n"
     ]
    }
   ],
   "source": [
    "draw_sixth_random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped table: opensea_nfts\n",
      "Dropped table: rarible_nfts\n",
      "Dropped table: magiceden_nfts\n",
      "Dropped table: atomic_nfts\n",
      "All tables except 'sampled_collections' and 'sqlite_sequence' have been dropped from 'random_sample_6.db'.\n"
     ]
    }
   ],
   "source": [
    "def drop_other_tables(db_path=\"random_sample_6.db\", keep_table=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Connects to 'db_path', enumerates all tables, \n",
    "    and drops any table that is not 'keep_table' or 'sqlite_sequence'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 1) Get all tables in the SQLite file\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    # 2) For each table, if it's not keep_table or 'sqlite_sequence', drop it\n",
    "    for tbl in tables:\n",
    "        if tbl not in [keep_table, \"sqlite_sequence\"]:\n",
    "            drop_sql = f\"DROP TABLE IF EXISTS '{tbl}'\"\n",
    "            cursor.execute(drop_sql)\n",
    "            print(f\"Dropped table: {tbl}\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"All tables except '{keep_table}' and 'sqlite_sequence' have been dropped from '{db_path}'.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    drop_other_tables(db_path=\"random_sample_6.db\", keep_table=\"sampled_collections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_opensea_nfts_table(db_path=\"random_sample_6.db\", table_name=\"opensea_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table with columns for the relevant fields from the OpenSea NFT JSON.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Create table if not exists\n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        \n",
    "        -- Linking field from 'sampled_collections' table\n",
    "        slug_name TEXT,\n",
    "        \n",
    "        -- Fields from the NFT JSON:\n",
    "        identifier TEXT,\n",
    "        contract TEXT,\n",
    "        token_standard TEXT,\n",
    "        name TEXT,\n",
    "        description TEXT,\n",
    "        image_url TEXT,\n",
    "        display_image_url TEXT,\n",
    "        display_animation_url TEXT,\n",
    "        metadata_url TEXT,\n",
    "        opensea_url TEXT,\n",
    "        updated_at TEXT,\n",
    "        is_disabled INTEGER,\n",
    "        is_nsfw INTEGER,\n",
    "        \n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_opensea_nfts(collection_slug, api_key, limit=10):\n",
    "    \"\"\"\n",
    "    Calls the OpenSea endpoint:\n",
    "      GET /api/v2/collection/{collection_slug}/nfts?limit={limit}\n",
    "    Returns the parsed JSON dict with:\n",
    "       { \"nfts\": [ { ... }, {...} ], \"next\": \"string\" }\n",
    "    If there's an error, returns an empty dict.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.opensea.io/api/v2/collection\"\n",
    "    url = f\"{base_url}/{collection_slug}/nfts\"\n",
    "    \n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": api_key\n",
    "    }\n",
    "    params = {\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    \n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[OpenSea NFT Fetch] Error {resp.status_code} for '{collection_slug}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def store_opensea_nfts(db_path, table_name, slug_name, nfts_data):\n",
    "    \"\"\"\n",
    "    Inserts each NFT from nfts_data[\"nfts\"] into opensea_nfts, linking them\n",
    "    via 'slug_name'. We do NOT store the 'collection' field from the JSON,\n",
    "    but instead rely on 'slug_name' to identify the parent collection.\n",
    "    \"\"\"\n",
    "    nfts_list = nfts_data.get(\"nfts\", [])\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        slug_name,\n",
    "        identifier,\n",
    "        contract,\n",
    "        token_standard,\n",
    "        name,\n",
    "        description,\n",
    "        image_url,\n",
    "        display_image_url,\n",
    "        display_animation_url,\n",
    "        metadata_url,\n",
    "        opensea_url,\n",
    "        updated_at,\n",
    "        is_disabled,\n",
    "        is_nsfw,\n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))\n",
    "    \"\"\"\n",
    "    \n",
    "    for nft in nfts_list:\n",
    "        identifier = nft.get(\"identifier\", \"\")\n",
    "        contract = nft.get(\"contract\", \"\")\n",
    "        token_standard = nft.get(\"token_standard\", \"\")\n",
    "        name = nft.get(\"name\", \"\")\n",
    "        desc = nft.get(\"description\", \"\")\n",
    "        image_url = nft.get(\"image_url\", \"\")\n",
    "        display_image = nft.get(\"display_image_url\", \"\")\n",
    "        display_animation = nft.get(\"display_animation_url\", \"\")\n",
    "        metadata_url = nft.get(\"metadata_url\", \"\")\n",
    "        opensea_url = nft.get(\"opensea_url\", \"\")\n",
    "        updated_at = nft.get(\"updated_at\", \"\")\n",
    "        \n",
    "        # Convert booleans to int (1/0)\n",
    "        is_disabled = 1 if nft.get(\"is_disabled\", False) else 0\n",
    "        is_nsfw = 1 if nft.get(\"is_nsfw\", False) else 0\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            slug_name,\n",
    "            identifier,\n",
    "            contract,\n",
    "            token_standard,\n",
    "            name,\n",
    "            desc,\n",
    "            image_url,\n",
    "            display_image,\n",
    "            display_animation,\n",
    "            metadata_url,\n",
    "            opensea_url,\n",
    "            updated_at,\n",
    "            is_disabled,\n",
    "            is_nsfw\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def fetch_opensea_nfts_for_collections(db_path=\"random_sample_6.db\", table_collections=\"sampled_collections\",\n",
    "                                       table_nfts=\"opensea_nfts\", api_key=\"YOUR_API_KEY\", limit=10):\n",
    "    \"\"\"\n",
    "    1) Ensure 'opensea_nfts' table exists.\n",
    "    2) Query 'sampled_collections' for marketplace='OpenSea', using 'slug_name'\n",
    "    3) For each, fetch up to {limit} items from OpenSea.\n",
    "    4) Store them in 'opensea_nfts'.\n",
    "    \"\"\"\n",
    "    # Create table if not exists\n",
    "    create_opensea_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Query the relevant rows\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    for idx, (slug,) in enumerate(rows, start=1):\n",
    "        print(f\"[{idx}/{len(rows)}] Fetching up to {limit} NFTs for slug='{slug}'\")\n",
    "        nfts_data = fetch_opensea_nfts(slug, api_key, limit=limit)\n",
    "        store_opensea_nfts(db_path, table_nfts, slug, nfts_data)\n",
    "    \n",
    "    print(\"Done fetching NFT data for all OpenSea collections in random_sample_6.db.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/16] Fetching up to 10 NFTs for slug='lens-collect-profile-199929-publication-3'\n",
      "[2/16] Fetching up to 10 NFTs for slug='municipios-del-futuro-cluster-de-iot-de-la-comunid'\n",
      "[3/16] Fetching up to 10 NFTs for slug='hypio'\n",
      "[4/16] Fetching up to 10 NFTs for slug='dragon-crypto-hero'\n",
      "[5/16] Fetching up to 10 NFTs for slug='summer-vibe-10'\n",
      "[6/16] Fetching up to 10 NFTs for slug='family-edition'\n",
      "[7/16] Fetching up to 10 NFTs for slug='xlfrw'\n",
      "[8/16] Fetching up to 10 NFTs for slug='sudocat-flow'\n",
      "[9/16] Fetching up to 10 NFTs for slug='glow-panda-genesis'\n",
      "[10/16] Fetching up to 10 NFTs for slug='delfin-ohno-blast'\n",
      "[11/16] Fetching up to 10 NFTs for slug='dancing-girls-in-color'\n",
      "[12/16] Fetching up to 10 NFTs for slug='personas-3'\n",
      "[13/16] Fetching up to 10 NFTs for slug='zora-1531'\n",
      "[14/16] Fetching up to 10 NFTs for slug='how-to-pod'\n",
      "[15/16] Fetching up to 10 NFTs for slug='open-ticketing-ecosystem-event-8355'\n",
      "[16/16] Fetching up to 10 NFTs for slug='stained-glasswindows'\n",
      "Done fetching NFT data for all OpenSea collections in random_sample_6.db.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENSEA_API_KEY = \"your_key\"\n",
    "    fetch_opensea_nfts_for_collections(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"opensea_nfts\",\n",
    "        api_key=OPENSEA_API_KEY,\n",
    "        limit=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_columns_if_not_exists(db_path=\"random_sample_6.db\", table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Adds the column 'total_supply' to the 'sampled_collections' table\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    cols_to_add = [\n",
    "        (\"total_supply\", \"REAL\")\n",
    "    ]\n",
    "    \n",
    "    for col, col_type in cols_to_add:\n",
    "        alter_stmt = f\"ALTER TABLE {table_name} ADD COLUMN {col} {col_type}\"\n",
    "        try:\n",
    "            c.execute(alter_stmt)\n",
    "            print(f\"Added column '{col}' to {table_name}\")\n",
    "        except sqlite3.OperationalError as e:\n",
    "            # Likely column already exists\n",
    "            pass\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_opensea_collection_details(slug, api_key):\n",
    "    \"\"\"\n",
    "    Calls the endpoint:\n",
    "      GET https://api.opensea.io/api/v2/collections/{collection_slug}\n",
    "    Returns a dict with keys:\n",
    "       'collection', 'name', 'total_supply', 'created_date', 'fees' (list), etc.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.opensea.io/api/v2/collections/{slug}\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": api_key\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json() \n",
    "    else:\n",
    "        print(f\"[OpenSea Collection Fetch] Error {resp.status_code} for slug='{slug}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def update_opensea_collection_data(db_path, table_name, slug, data):\n",
    "    \"\"\"\n",
    "    data has: 'created_date', 'total_supply', 'fees' list, etc.\n",
    "    We map:\n",
    "       created_date -> created_time\n",
    "       total_supply -> total_supply\n",
    "       fees[0].fee -> marketplace_fee\n",
    "       fees[1].fee -> royalty_fee (if exist)\n",
    "    Then do UPDATE on the row with marketplace='OpenSea' AND slug_name=?\n",
    "    \"\"\"\n",
    "    collection_slug = data.get(\"collection\", slug)  # fallback to slug if missing\n",
    "    created_date = data.get(\"created_date\", None)   # string\n",
    "    total_supply = data.get(\"total_supply\", 0.0)\n",
    "    fees = data.get(\"fees\", [])\n",
    "    \n",
    "    marketplace_fee = None\n",
    "    royalty_fee = None\n",
    "    \n",
    "    if len(fees) >= 1:\n",
    "        # first fee => marketplace fee\n",
    "        marketplace_fee = fees[0].get(\"fee\", 0.0)\n",
    "    if len(fees) >= 2:\n",
    "        # second fee => royalty fee\n",
    "        royalty_fee = fees[1].get(\"fee\", 0.0)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    update_stmt = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET created_time = ?,\n",
    "        total_supply = ?,\n",
    "        marketplace_fee = ?,\n",
    "        royalty_fee = ?\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name=?\n",
    "    \"\"\"\n",
    "    c.execute(update_stmt, (\n",
    "        created_date,\n",
    "        total_supply,\n",
    "        marketplace_fee,\n",
    "        royalty_fee,\n",
    "        slug\n",
    "    ))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_and_update_opensea_collection_data(db_path=\"random_sample_6.db\", table_name=\"sampled_collections\",\n",
    "                                             api_key=\"YOUR_API_KEY\"):\n",
    "    \"\"\"\n",
    "    # 1) Ensure the new columns exist in the 'sampled_collections' table.\n",
    "    # 2) Query all rows for marketplace='OpenSea'.\n",
    "    # 3) For each slug_name, call the new endpoint to fetch additional data,\n",
    "    #    then update the row with created_time, total_supply, marketplace_fee, royalty_fee.\n",
    "    # \"\"\"\n",
    "\n",
    "    add_new_columns_if_not_exists()\n",
    "    \n",
    "    # 2) Query the existing table\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "        SELECT slug_name\n",
    "        FROM {table_name}\n",
    "        WHERE marketplace='OpenSea'\n",
    "          AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    for idx, (slug,) in enumerate(rows, start=1):\n",
    "        print(f\"[{idx}/{len(rows)}] Fetching extended data for slug='{slug}'\")\n",
    "        data = fetch_opensea_collection_details(slug, api_key)\n",
    "        if data:\n",
    "            # parse JSON: top-level fields => data\n",
    "            # The endpoint returns { \"collection\": \"string\", \"name\": \"string\", ...}\n",
    "            # We just pass it to update\n",
    "            update_opensea_collection_data(db_path, table_name, slug, data)\n",
    "            \n",
    "        # optional short sleep to avoid rate-limiting\n",
    "        # time.sleep(0.2)\n",
    "\n",
    "    print(\"Done updating additional data for all OpenSea collections in random_sample_6.db.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added column 'total_supply' to sampled_collections\n",
      "[1/16] Fetching extended data for slug='lens-collect-profile-199929-publication-3'\n",
      "[2/16] Fetching extended data for slug='municipios-del-futuro-cluster-de-iot-de-la-comunid'\n",
      "[3/16] Fetching extended data for slug='hypio'\n",
      "[4/16] Fetching extended data for slug='dragon-crypto-hero'\n",
      "[5/16] Fetching extended data for slug='summer-vibe-10'\n",
      "[6/16] Fetching extended data for slug='family-edition'\n",
      "[7/16] Fetching extended data for slug='xlfrw'\n",
      "[8/16] Fetching extended data for slug='sudocat-flow'\n",
      "[9/16] Fetching extended data for slug='glow-panda-genesis'\n",
      "[10/16] Fetching extended data for slug='delfin-ohno-blast'\n",
      "[11/16] Fetching extended data for slug='dancing-girls-in-color'\n",
      "[12/16] Fetching extended data for slug='personas-3'\n",
      "[13/16] Fetching extended data for slug='zora-1531'\n",
      "[14/16] Fetching extended data for slug='how-to-pod'\n",
      "[15/16] Fetching extended data for slug='open-ticketing-ecosystem-event-8355'\n",
      "[16/16] Fetching extended data for slug='stained-glasswindows'\n",
      "Done updating additional data for all OpenSea collections in random_sample_6.db.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENSEA_API_KEY = \"your_key\"\n",
    "    fetch_and_update_opensea_collection_data(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_name=\"sampled_collections\",\n",
    "        api_key=OPENSEA_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_traits_json_column_if_not_exists(db_path=\"random_sample_6.db\", table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Adds a 'traits_json' column to the 'sampled_collections' table if it does not exist.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Attempt an ALTER TABLE for 'traits_json'\n",
    "    alter_stmt = f\"ALTER TABLE {table_name} ADD COLUMN traits_json TEXT\"\n",
    "    try:\n",
    "        c.execute(alter_stmt)\n",
    "        print(f\"Added 'traits_json' column to {table_name}\")\n",
    "    except sqlite3.OperationalError:\n",
    "        # Column probably already exists\n",
    "        pass\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_opensea_traits(collection_slug, api_key):\n",
    "    \"\"\"\n",
    "    Calls the OpenSea endpoint:\n",
    "    GET /api/v2/traits/{collection_slug}\n",
    "    \n",
    "    Returns JSON like:\n",
    "      {\n",
    "        \"categories\": {...},\n",
    "        \"counts\": {...}\n",
    "      }\n",
    "    \"\"\"\n",
    "    url = f\"https://api.opensea.io/api/v2/traits/{collection_slug}\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"x-api-key\": api_key\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[OpenSea Traits] Error {resp.status_code} for slug='{collection_slug}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def store_traits_json_in_collections(db_path, table_name, slug_name, traits_data):\n",
    "    \"\"\"\n",
    "    Updates the 'sampled_collections' table with the entire traits JSON\n",
    "    in the 'traits_json' column for the given slug_name.\n",
    "    \n",
    "    We assume marketplace='OpenSea' is the row filter.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    update_stmt = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET traits_json = ?\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name=?\n",
    "    \"\"\"\n",
    "    c.execute(update_stmt, (json.dumps(traits_data), slug_name))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "def fetch_and_update_opensea_traits_in_collections(db_path=\"random_sample_6.db\",\n",
    "                                                   table_name=\"sampled_collections\",\n",
    "                                                   api_key=\"YOUR_API_KEY\"):\n",
    "    \"\"\"\n",
    "    1) Ensure 'traits_json' column exists in 'sampled_collections'.\n",
    "    2) Query all rows where marketplace='OpenSea' and slug_name is not null.\n",
    "    3) For each slug_name, fetch traits JSON from /api/v2/traits/{slug_name} and\n",
    "       store it in the 'traits_json' column.\n",
    "    \"\"\"\n",
    "    # 1) Add 'traits_json' column if needed\n",
    "    add_traits_json_column_if_not_exists(db_path, table_name)\n",
    "    \n",
    "    # 2) Query the existing table for OpenSea slugs\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='OpenSea'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    # 3) For each slug, fetch traits and store\n",
    "    for idx, (slug,) in enumerate(rows, start=1):\n",
    "        print(f\"[{idx}/{len(rows)}] Fetching traits for slug='{slug}'\")\n",
    "        traits_data = fetch_opensea_traits(slug, api_key)\n",
    "        store_traits_json_in_collections(db_path, table_name, slug, traits_data)\n",
    "    \n",
    "    print(f\"Done updating 'traits_json' for all OpenSea collections in {table_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 'traits_json' column to sampled_collections\n",
      "[1/16] Fetching traits for slug='lens-collect-profile-199929-publication-3'\n",
      "[2/16] Fetching traits for slug='municipios-del-futuro-cluster-de-iot-de-la-comunid'\n",
      "[3/16] Fetching traits for slug='hypio'\n",
      "[4/16] Fetching traits for slug='dragon-crypto-hero'\n",
      "[5/16] Fetching traits for slug='summer-vibe-10'\n",
      "[6/16] Fetching traits for slug='family-edition'\n",
      "[7/16] Fetching traits for slug='xlfrw'\n",
      "[8/16] Fetching traits for slug='sudocat-flow'\n",
      "[9/16] Fetching traits for slug='glow-panda-genesis'\n",
      "[10/16] Fetching traits for slug='delfin-ohno-blast'\n",
      "[11/16] Fetching traits for slug='dancing-girls-in-color'\n",
      "[12/16] Fetching traits for slug='personas-3'\n",
      "[13/16] Fetching traits for slug='zora-1531'\n",
      "[14/16] Fetching traits for slug='how-to-pod'\n",
      "[15/16] Fetching traits for slug='open-ticketing-ecosystem-event-8355'\n",
      "[16/16] Fetching traits for slug='stained-glasswindows'\n",
      "Done updating 'traits_json' for all OpenSea collections in sampled_collections.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    OPENSEA_API_KEY = \"your_key\"\n",
    "    fetch_and_update_opensea_traits_in_collections(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_name=\"sampled_collections\",\n",
    "        api_key=OPENSEA_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rarible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_collection_id(collection_id_blockchain):\n",
    "    \"\"\"\n",
    "    Given a string like '0x594824a3d6e5777b3c7cc202ad1050435aac7698:ethereum',\n",
    "    transform it into 'ETHEREUM:0x594824a3d6e5777b3c7cc202ad1050435aac7698'\n",
    "    for Rarible's endpoint: ?collectionIds=ETHEREUM%3A0x..\n",
    "    \"\"\"\n",
    "    if \":\" not in collection_id_blockchain:\n",
    "        return None\n",
    "    coll_id, chain = collection_id_blockchain.split(\":\")\n",
    "    return f\"{chain.upper()}:{coll_id}\"\n",
    "\n",
    "def fetch_rarible_traits_single(collection_id_rarible, api_key):\n",
    "    \"\"\"\n",
    "    Calls Rarible's endpoint, single collection ID:\n",
    "      GET /v0.1/items/traits?collectionIds={collection_id_rarible}\n",
    "\n",
    "    Returns the JSON with structure:\n",
    "      {\n",
    "        \"continuation\": \"string\",\n",
    "        \"traits\": [ { \"key\": {...}, \"values\": [...] }, ... ]\n",
    "      }\n",
    "    \"\"\"\n",
    "    base_url = \"https://api.rarible.org/v0.1/items/traits\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"X-API-KEY\": api_key\n",
    "    }\n",
    "    # For a single ID, just pass collectionIds once\n",
    "    params = {\n",
    "        \"collectionIds\": collection_id_rarible\n",
    "    }\n",
    "    resp = requests.get(base_url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[Rarible Traits] Error {resp.status_code} => {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def update_traits_json_for_rarible(db_path=\"random_sample_6.db\",\n",
    "                                   table_name=\"sampled_collections\",\n",
    "                                   api_key=\"YOUR_RARIBLE_API_KEY\"):\n",
    "    \"\"\"\n",
    "    1) Query 'sampled_collections' where marketplace='Rarible'\n",
    "    2) For each row, transform 'collection_id' to Rarible format, fetch traits,\n",
    "       store entire JSON in 'traits_json' column\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # We'll assume 'traits_json' column already exists (like for OpenSea).\n",
    "    # If not, you'll need the add_column logic from your previous script.\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    SELECT collection_id\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='Rarible'\n",
    "      AND collection_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} Rarible collections to fetch traits for.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (orig_id,) in rows:\n",
    "        rarible_id = transform_collection_id(orig_id)\n",
    "        if rarible_id is None:\n",
    "            print(f\"Skipping invalid format => {orig_id}\")\n",
    "            continue\n",
    "        \n",
    "        data = fetch_rarible_traits_single(rarible_id, api_key)\n",
    "        \n",
    "        # Now update the 'traits_json' in that row\n",
    "        conn2 = sqlite3.connect(db_path)\n",
    "        c2 = conn2.cursor()\n",
    "        update_stmt = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET traits_json = ?\n",
    "        WHERE marketplace='Rarible'\n",
    "          AND collection_id=?\n",
    "        \"\"\"\n",
    "        c2.execute(update_stmt, (json.dumps(data), orig_id))\n",
    "        conn2.commit()\n",
    "        conn2.close()\n",
    "        \n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Updated 'traits_json' for => {orig_id}\")\n",
    "    \n",
    "    print(\"Done fetching/storing Rarible traits in 'traits_json' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 Rarible collections to fetch traits for.\n",
      "[1/13] Updated 'traits_json' for => 0xf3e599db00a9a41785b619cbc87c86019349dda5:lisk\n",
      "[2/13] Updated 'traits_json' for => 0x436119dafa0e5160aa17e310da858ccfeb937c4e:ethereum\n",
      "[3/13] Updated 'traits_json' for => 0x38aebd5ad1b71374cc59f5f1271c29e3cfb62caa:rari\n",
      "[4/13] Updated 'traits_json' for => 0xbefc6b1ac05ecff75f8f1866d801e990d01dc0bd:telos\n",
      "[5/13] Updated 'traits_json' for => 0x4e042f1d2f24ad0794a24a7a42d58b7c73f766af:kroma\n",
      "[6/13] Updated 'traits_json' for => 0xb7be41cfb1eb2f15c16e144ba2e90eb8828749ab:kroma\n",
      "[7/13] Updated 'traits_json' for => 0x471c250781cd7a64ab37f227e9ceee956cc9ca7a:base\n",
      "[8/13] Updated 'traits_json' for => 0x193ba2c46519459ad536ea580978faffef575ba7:polygon\n",
      "[9/13] Updated 'traits_json' for => 0x55b1316d3065f4f88733d0aed9632a5ab8906ebd:base\n",
      "[10/13] Updated 'traits_json' for => 0x735d8a60455acf37a617e241163e2d593b9eb439:base\n",
      "[11/13] Updated 'traits_json' for => 0xe6d1b14467afaf1dab6cab4c484b67da214937e8:immutablex\n",
      "[12/13] Updated 'traits_json' for => 0x6aeb5e6f18826f33debd54bfac55dae3bfa677dd:celo\n",
      "[13/13] Updated 'traits_json' for => 0x1a5de3bac5917a806cdaaac29a4391e517794ce5:base\n",
      "Done fetching/storing Rarible traits in 'traits_json' column.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    RARIBLE_API_KEY = \"your_key\"\n",
    "    update_traits_json_for_rarible(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_name=\"sampled_collections\",\n",
    "        api_key=RARIBLE_API_KEY\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rarible_nfts_table(db_path=\"random_sample_6.db\", table_name=\"rarible_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table 'rarible_nfts' with columns similar to 'opensea_nfts',\n",
    "    storing key fields from the Rarible item-level data plus a link back \n",
    "    to 'collection_id' in 'sampled_collections'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        -- references the original 'id:blockchain' format from 'sampled_collections'\n",
    "        collection_id TEXT,\n",
    "        \n",
    "        item_id TEXT,          -- item[\"id\"] e.g. \"ETHEREUM:0xb66a6...:123\"\n",
    "        blockchain TEXT,       -- item[\"blockchain\"]\n",
    "        contract TEXT,         -- item[\"contract\"]\n",
    "        token_id TEXT,         -- item[\"tokenId\"]\n",
    "        \n",
    "        name TEXT,             -- from item[\"meta\"][\"name\"]\n",
    "        description TEXT,      -- from item[\"meta\"][\"description\"]\n",
    "        image_url TEXT,        -- optional, if we parse item[\"meta\"][\"content\"] for an image\n",
    "        minted_at TEXT,        -- item[\"mintedAt\"]\n",
    "        last_updated TEXT,     -- item[\"lastUpdatedAt\"]\n",
    "        supply REAL,           -- item[\"supply\"] \n",
    "        owner_if_single TEXT,  -- item[\"ownerIfSingle\"] if we want\n",
    "        \n",
    "        project_url TEXT,      -- e.g. item[\"meta\"][\"externalUri\"] if present\n",
    "        created_at TEXT,       -- item[\"meta\"][\"createdAt\"]\n",
    "        \n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_collection_id_for_rarible(orig_id):\n",
    "    \"\"\"\n",
    "    Convert 'id:blockchain' => 'BLOCKCHAIN:0xid' for use in Rarible API.\n",
    "    e.g. '0x5948abcd:ethereum' => 'ETHEREUM:0x5948abcd'\n",
    "    \"\"\"\n",
    "    if \":\" not in orig_id:\n",
    "        return None\n",
    "    coll_id, chain = orig_id.split(\":\")\n",
    "    return f\"{chain.upper()}:{coll_id}\"\n",
    "\n",
    "def fetch_rarible_nfts(collection_param, api_key, size=10):\n",
    "    \"\"\"\n",
    "    Calls Rarible endpoint:\n",
    "      GET /v0.1/items/byCollection?collection={collection_param}&size={size}\n",
    "    e.g. collection_param = 'ETHEREUM:0xb66a603f...'\n",
    "    Returns a dict with keys 'continuation' and 'items' (list).\n",
    "    \"\"\"\n",
    "    url = \"https://api.rarible.org/v0.1/items/byCollection\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"X-API-KEY\": api_key\n",
    "    }\n",
    "    params = {\n",
    "        \"collection\": collection_param,\n",
    "        \"size\": size\n",
    "    }\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[Rarible NFT Fetch] Error {resp.status_code} => {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def store_rarible_nfts(db_path, table_name, orig_id, items_list):\n",
    "    \"\"\"\n",
    "    Insert up to 10 items into 'rarible_nfts' table, storing relevant fields.\n",
    "    :param orig_id: The original 'id:blockchain' used in 'sampled_collections'\n",
    "    :param items_list: list of item dicts from the Rarible API\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        collection_id,\n",
    "        item_id,\n",
    "        blockchain,\n",
    "        contract,\n",
    "        token_id,\n",
    "        name,\n",
    "        description,\n",
    "        image_url,\n",
    "        minted_at,\n",
    "        last_updated,\n",
    "        supply,\n",
    "        owner_if_single,\n",
    "        project_url,\n",
    "        created_at,\n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in items_list:\n",
    "        item_id = item.get(\"id\", \"\")\n",
    "        blockchain = item.get(\"blockchain\", \"\")\n",
    "        contract = item.get(\"contract\", \"\")\n",
    "        token_id = str(item.get(\"tokenId\", \"\"))\n",
    "        supply = item.get(\"supply\", 0)\n",
    "        minted_at = item.get(\"mintedAt\", \"\")\n",
    "        last_updated = item.get(\"lastUpdatedAt\", \"\")\n",
    "        owner_if_single = item.get(\"ownerIfSingle\", \"\")\n",
    "        \n",
    "        meta = item.get(\"meta\", {})\n",
    "        name = meta.get(\"name\", \"\")\n",
    "        description = meta.get(\"description\", \"\")\n",
    "        created_at = meta.get(\"createdAt\", \"\")\n",
    "        project_url = meta.get(\"externalUri\", \"\")\n",
    "        \n",
    "        # Optional: parse meta[\"content\"] for image\n",
    "        # The example doesn't show a direct \"url\", so we may store 'N/A' or parse further\n",
    "        content_list = meta.get(\"content\", [])\n",
    "        image_url = \"N/A\"\n",
    "        for content_obj in content_list:\n",
    "            # if there's a recognized URL, parse it\n",
    "            # The example lacks a 'url' field, so we skip. \n",
    "            # If your real data has it, you might do:\n",
    "            # image_url = content_obj.get(\"url\", \"N/A\")\n",
    "            # break\n",
    "            pass\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            orig_id,      # collection_id (as it appears in 'sampled_collections')\n",
    "            item_id,\n",
    "            blockchain,\n",
    "            contract,\n",
    "            token_id,\n",
    "            name,\n",
    "            description,\n",
    "            image_url,\n",
    "            minted_at,\n",
    "            last_updated,\n",
    "            supply,\n",
    "            owner_if_single,\n",
    "            project_url,\n",
    "            created_at\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_rarible_nfts_for_collections(db_path=\"random_sample_6.db\", table_collections=\"sampled_collections\",\n",
    "                                       table_nfts=\"rarible_nfts\", api_key=\"YOUR_RARIBLE_API_KEY\", size=10):\n",
    "    \"\"\"\n",
    "    1) Create the 'rarible_nfts' table if not exists.\n",
    "    2) Query 'sampled_collections' where marketplace='Rarible'.\n",
    "    3) Transform 'collection_id:blockchain' to 'BLOCKCHAIN:collection_id'.\n",
    "    4) Fetch items (size=10) from Rarible's endpoint.\n",
    "    5) Store them in 'rarible_nfts'.\n",
    "    \"\"\"\n",
    "    # 1) create table\n",
    "    create_rarible_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    # 2) query the relevant rows\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT collection_id\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='Rarible'\n",
    "      AND collection_id IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    count = 0\n",
    "    for (orig_id,) in rows:\n",
    "        rarible_format = transform_collection_id_for_rarible(orig_id)\n",
    "        if not rarible_format:\n",
    "            print(f\"Skipping invalid format => {orig_id}\")\n",
    "            continue\n",
    "        \n",
    "        data = fetch_rarible_nfts(rarible_format, api_key, size=size)\n",
    "        items = data.get(\"items\", [])\n",
    "        \n",
    "        store_rarible_nfts(db_path, table_nfts, orig_id, items)\n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Inserted up to {len(items)} items for {orig_id}\")\n",
    "    \n",
    "    print(\"Done fetching and storing Rarible NFTs in\", table_nfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/13] Inserted up to 2 items for 0xf3e599db00a9a41785b619cbc87c86019349dda5:lisk\n",
      "[2/13] Inserted up to 0 items for 0x436119dafa0e5160aa17e310da858ccfeb937c4e:ethereum\n",
      "[3/13] Inserted up to 10 items for 0x38aebd5ad1b71374cc59f5f1271c29e3cfb62caa:rari\n",
      "[4/13] Inserted up to 4 items for 0xbefc6b1ac05ecff75f8f1866d801e990d01dc0bd:telos\n",
      "[5/13] Inserted up to 1 items for 0x4e042f1d2f24ad0794a24a7a42d58b7c73f766af:kroma\n",
      "[6/13] Inserted up to 5 items for 0xb7be41cfb1eb2f15c16e144ba2e90eb8828749ab:kroma\n",
      "[7/13] Inserted up to 2 items for 0x471c250781cd7a64ab37f227e9ceee956cc9ca7a:base\n",
      "[8/13] Inserted up to 10 items for 0x193ba2c46519459ad536ea580978faffef575ba7:polygon\n",
      "[9/13] Inserted up to 0 items for 0x55b1316d3065f4f88733d0aed9632a5ab8906ebd:base\n",
      "[10/13] Inserted up to 10 items for 0x735d8a60455acf37a617e241163e2d593b9eb439:base\n",
      "[11/13] Inserted up to 10 items for 0xe6d1b14467afaf1dab6cab4c484b67da214937e8:immutablex\n",
      "[12/13] Inserted up to 1 items for 0x6aeb5e6f18826f33debd54bfac55dae3bfa677dd:celo\n",
      "[13/13] Inserted up to 1 items for 0x1a5de3bac5917a806cdaaac29a4391e517794ce5:base\n",
      "Done fetching and storing Rarible NFTs in rarible_nfts\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    RARIBLE_API_KEY = \"your_key\"\n",
    "    fetch_rarible_nfts_for_collections(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"rarible_nfts\",\n",
    "        api_key=RARIBLE_API_KEY,\n",
    "        size=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MagicEden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_magiceden_attributes(slug_name):\n",
    "    base_url = \"https://api-mainnet.magiceden.dev/v2/collections\"\n",
    "    url = f\"{base_url}/{slug_name}/attributes\"\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    \n",
    "    resp = requests.get(url, headers=headers)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[MagicEden Attributes] Error {resp.status_code} for slug='{slug_name}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def store_traits_json_for_magiceden(db_path, table_name, slug_name, traits_data):\n",
    "    \"\"\"\n",
    "    Updates the 'sampled_collections' row for marketplace='MagicEden'\n",
    "    and the given slug_name, setting the entire JSON in 'traits_json'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    update_sql = f\"\"\"\n",
    "    UPDATE {table_name}\n",
    "    SET traits_json = ?\n",
    "    WHERE marketplace='MagicEden'\n",
    "      AND slug_name=?\n",
    "    \"\"\"\n",
    "    c.execute(update_sql, (json.dumps(traits_data), slug_name))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_and_update_magiceden_traits(db_path=\"random_sample_6.db\", table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    1) Query 'sampled_collections' for rows with marketplace='MagicEden'.\n",
    "    2) For each 'slug_name', call fetch_magiceden_attributes(slug_name).\n",
    "    3) Store the JSON result in 'traits_json' column of the same row.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # We'll fetch all MagicEden slug_names\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='MagicEden'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} Magic Eden collections to update 'traits_json'.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (slug_name,) in rows:\n",
    "        data = fetch_magiceden_attributes(slug_name)\n",
    "        store_traits_json_for_magiceden(db_path, table_name, slug_name, data)\n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Updated 'traits_json' for slug='{slug_name}'\")\n",
    "    \n",
    "    print(\"Done fetching/storing Magic Eden attributes in 'traits_json'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 Magic Eden collections to update 'traits_json'.\n",
      "[1/13] Updated 'traits_json' for slug='titan_whales'\n",
      "[2/13] Updated 'traits_json' for slug='yetiz'\n",
      "[3/13] Updated 'traits_json' for slug='heavenland'\n",
      "[4/13] Updated 'traits_json' for slug='the_frontier'\n",
      "[5/13] Updated 'traits_json' for slug='cyberspies'\n",
      "[6/13] Updated 'traits_json' for slug='coast2coast'\n",
      "[7/13] Updated 'traits_json' for slug='metavillagemansions'\n",
      "[8/13] Updated 'traits_json' for slug='neon_clouds_collective'\n",
      "[9/13] Updated 'traits_json' for slug='oak_paradise'\n",
      "[10/13] Updated 'traits_json' for slug='skatex_events'\n",
      "[11/13] Updated 'traits_json' for slug='cool_penguin_squad'\n",
      "[12/13] Updated 'traits_json' for slug='mrclpass'\n",
      "[13/13] Updated 'traits_json' for slug='pawspaws'\n",
      "Done fetching/storing Magic Eden attributes in 'traits_json'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fetch_and_update_magiceden_traits(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_name=\"sampled_collections\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_magiceden_nfts_table(db_path=\"random_sample_6.db\", table_name=\"magiceden_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table 'magiceden_nfts' with columns for relevant fields from\n",
    "    the Magic Eden listing JSON, plus a link back to 'sampled_collections' via slug_name.\n",
    "    \n",
    "    We'll have 27 columns total:\n",
    "      1) id (PK)\n",
    "      2) collection_slug\n",
    "      ...\n",
    "      26) token_properties_json\n",
    "      27) fetched_at\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # Below we define 27 columns total\n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        \n",
    "        collection_slug TEXT,\n",
    "\n",
    "        pdaAddress TEXT,\n",
    "        auctionHouse TEXT,\n",
    "        tokenAddress TEXT,\n",
    "        tokenMint TEXT,\n",
    "        seller TEXT,\n",
    "        sellerReferral TEXT,\n",
    "        tokenSize REAL,\n",
    "        price REAL,\n",
    "        expiry REAL,\n",
    "        \n",
    "        rarity_json TEXT,\n",
    "        extra_json TEXT,\n",
    "        listingSource TEXT,\n",
    "        \n",
    "        token_mintAddress TEXT,\n",
    "        token_owner TEXT,\n",
    "        token_supply REAL,\n",
    "        token_collection TEXT,\n",
    "        token_name TEXT,\n",
    "        token_updateAuthority TEXT,\n",
    "        token_primarySaleHappened INTEGER,\n",
    "        token_sellerFeeBasisPoints REAL,\n",
    "        token_image TEXT,\n",
    "        token_animationUrl TEXT,\n",
    "        token_externalUrl TEXT,\n",
    "        \n",
    "        token_attributes_json TEXT,\n",
    "        token_properties_json TEXT,\n",
    "        \n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_magiceden_listings(collection_slug, limit=10):\n",
    "    \"\"\"\n",
    "    GET https://api-mainnet.magiceden.dev/v2/collections/{collection_slug}/listings?limit={limit}\n",
    "    Returns a list of dicts if successful, else empty list.\n",
    "    \"\"\"\n",
    "    base_url = \"https://api-mainnet.magiceden.dev/v2/collections\"\n",
    "    url = f\"{base_url}/{collection_slug}/listings\"\n",
    "    params = {\"limit\": limit}\n",
    "    headers = {\"accept\": \"application/json\"}\n",
    "    \n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()  # Should be a list of listing dicts\n",
    "    else:\n",
    "        print(f\"[MagicEden NFT Fetch] Error {resp.status_code} for slug='{collection_slug}': {resp.text}\")\n",
    "        return []\n",
    "\n",
    "def store_magiceden_nfts(db_path, table_name, slug_name, listings):\n",
    "    \"\"\"\n",
    "    Insert each listing item into 'magiceden_nfts'.\n",
    "    We must provide EXACTLY 26 placeholders for these columns (excluding 'id' + including 'fetched_at' as a datetime call).\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    # 27 columns total => 'id' is autoincrement, so we have 26 placeholders\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        collection_slug,\n",
    "        \n",
    "        pdaAddress,\n",
    "        auctionHouse,\n",
    "        tokenAddress,\n",
    "        tokenMint,\n",
    "        seller,\n",
    "        sellerReferral,\n",
    "        tokenSize,\n",
    "        price,\n",
    "        expiry,\n",
    "        \n",
    "        rarity_json,\n",
    "        extra_json,\n",
    "        listingSource,\n",
    "        \n",
    "        token_mintAddress,\n",
    "        token_owner,\n",
    "        token_supply,\n",
    "        token_collection,\n",
    "        token_name,\n",
    "        token_updateAuthority,\n",
    "        token_primarySaleHappened,\n",
    "        token_sellerFeeBasisPoints,\n",
    "        token_image,\n",
    "        token_animationUrl,\n",
    "        token_externalUrl,\n",
    "        \n",
    "        token_attributes_json,\n",
    "        token_properties_json,\n",
    "        \n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (\n",
    "        ?,  -- collection_slug\n",
    "        ?,  -- pdaAddress\n",
    "        ?,  -- auctionHouse\n",
    "        ?,  -- tokenAddress\n",
    "        ?,  -- tokenMint\n",
    "        ?,  -- seller\n",
    "        ?,  -- sellerReferral\n",
    "        ?,  -- tokenSize\n",
    "        ?,  -- price\n",
    "        ?,  -- expiry\n",
    "        ?,  -- rarity_json\n",
    "        ?,  -- extra_json\n",
    "        ?,  -- listingSource\n",
    "        ?,  -- token_mintAddress\n",
    "        ?,  -- token_owner\n",
    "        ?,  -- token_supply\n",
    "        ?,  -- token_collection\n",
    "        ?,  -- token_name\n",
    "        ?,  -- token_updateAuthority\n",
    "        ?,  -- token_primarySaleHappened\n",
    "        ?,  -- token_sellerFeeBasisPoints\n",
    "        ?,  -- token_image\n",
    "        ?,  -- token_animationUrl\n",
    "        ?,  -- token_externalUrl\n",
    "        ?,  -- token_attributes_json\n",
    "        ?,  -- token_properties_json\n",
    "        datetime('now')  -- fetched_at\n",
    "    )\n",
    "    \"\"\"\n",
    "    # Notice we have exactly 26 placeholders (the last column uses datetime('now')).\n",
    "\n",
    "    for listing in listings:\n",
    "        pdaAddress = listing.get(\"pdaAddress\", \"\")\n",
    "        auctionHouse = listing.get(\"auctionHouse\", \"\")\n",
    "        tokenAddress = listing.get(\"tokenAddress\", \"\")\n",
    "        tokenMint = listing.get(\"tokenMint\", \"\")\n",
    "        seller = listing.get(\"seller\", \"\")\n",
    "        sellerReferral = listing.get(\"sellerReferral\", \"\")\n",
    "        tokenSize = listing.get(\"tokenSize\", 0)\n",
    "        price = listing.get(\"price\", 0)\n",
    "        expiry = listing.get(\"expiry\", 0)\n",
    "        \n",
    "        # Convert 'rarity' and 'extra' to JSON strings\n",
    "        rarity_json = json.dumps(listing.get(\"rarity\", {}))\n",
    "        extra_json = json.dumps(listing.get(\"extra\", {}))\n",
    "        \n",
    "        listingSource = listing.get(\"listingSource\", \"\")\n",
    "        \n",
    "        token_obj = listing.get(\"token\", {})\n",
    "        token_mintAddress = token_obj.get(\"mintAddress\", \"\")\n",
    "        token_owner = token_obj.get(\"owner\", \"\")\n",
    "        token_supply = token_obj.get(\"supply\", 0)\n",
    "        token_collection = token_obj.get(\"collection\", \"\")\n",
    "        token_name = token_obj.get(\"name\", \"\")\n",
    "        token_updateAuthority = token_obj.get(\"updateAuthority\", \"\")\n",
    "        \n",
    "        primarySaleHappened = 1 if token_obj.get(\"primarySaleHappened\", False) else 0\n",
    "        sellerFeeBasisPoints = token_obj.get(\"sellerFeeBasisPoints\", 0)\n",
    "        token_image = token_obj.get(\"image\", \"\")\n",
    "        token_animationUrl = token_obj.get(\"animationUrl\", \"\")\n",
    "        token_externalUrl = token_obj.get(\"externalUrl\", \"\")\n",
    "        \n",
    "        attributes_json = json.dumps(token_obj.get(\"attributes\", []))\n",
    "        properties_json = json.dumps(token_obj.get(\"properties\", {}))\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            slug_name,\n",
    "            pdaAddress,\n",
    "            auctionHouse,\n",
    "            tokenAddress,\n",
    "            tokenMint,\n",
    "            seller,\n",
    "            sellerReferral,\n",
    "            tokenSize,\n",
    "            price,\n",
    "            expiry,\n",
    "            rarity_json,\n",
    "            extra_json,\n",
    "            listingSource,\n",
    "            token_mintAddress,\n",
    "            token_owner,\n",
    "            token_supply,\n",
    "            token_collection,\n",
    "            token_name,\n",
    "            token_updateAuthority,\n",
    "            primarySaleHappened,\n",
    "            sellerFeeBasisPoints,\n",
    "            token_image,\n",
    "            token_animationUrl,\n",
    "            token_externalUrl,\n",
    "            attributes_json,\n",
    "            properties_json\n",
    "            # fetched_at => datetime('now') in SQL\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "def fetch_magiceden_nfts_for_collections(db_path=\"random_sample_6.db\",\n",
    "                                         table_collections=\"sampled_collections\",\n",
    "                                         table_nfts=\"magiceden_nfts\",\n",
    "                                         limit=10):\n",
    "    \"\"\"\n",
    "    Creates table if necessary, then for each row with marketplace='MagicEden',\n",
    "    uses 'slug_name' to fetch up to {limit} items from Magic Eden,\n",
    "    storing them in magiceden_nfts.\n",
    "    \"\"\"\n",
    "    create_magiceden_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='MagicEden'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    count = 0\n",
    "    for (slug_name,) in rows:\n",
    "        data = fetch_magiceden_listings(slug_name, limit=limit)\n",
    "        store_magiceden_nfts(db_path, table_nfts, slug_name, data)\n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Inserted up to {len(data)} items for MagicEden => {slug_name}\")\n",
    "    \n",
    "    print(f\"Done fetching/storing MagicEden listings in {table_nfts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/13] Inserted up to 10 items for MagicEden => titan_whales\n",
      "[2/13] Inserted up to 10 items for MagicEden => yetiz\n",
      "[3/13] Inserted up to 10 items for MagicEden => heavenland\n",
      "[4/13] Inserted up to 10 items for MagicEden => the_frontier\n",
      "[5/13] Inserted up to 1 items for MagicEden => cyberspies\n",
      "[6/13] Inserted up to 10 items for MagicEden => coast2coast\n",
      "[7/13] Inserted up to 5 items for MagicEden => metavillagemansions\n",
      "[8/13] Inserted up to 10 items for MagicEden => neon_clouds_collective\n",
      "[9/13] Inserted up to 10 items for MagicEden => oak_paradise\n",
      "[10/13] Inserted up to 10 items for MagicEden => skatex_events\n",
      "[11/13] Inserted up to 10 items for MagicEden => cool_penguin_squad\n",
      "[12/13] Inserted up to 1 items for MagicEden => mrclpass\n",
      "[13/13] Inserted up to 10 items for MagicEden => pawspaws\n",
      "Done fetching/storing MagicEden listings in magiceden_nfts\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fetch_magiceden_nfts_for_collections(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"magiceden_nfts\",\n",
    "        limit=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Atomic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_atomic_collection_stats(collection_name):\n",
    "    \"\"\"\n",
    "    Calls /atomicassets/v1/collections/{collection_name}/stats\"\n",
    "    \"\"\"\n",
    "    url = f\"https://wax.api.atomicassets.io/atomicassets/v1/collections/{collection_name}/stats\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()\n",
    "    else:\n",
    "        print(f\"[Atomic Stats] Error {resp.status_code} for collection='{collection_name}': {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def update_atomic_collection_total_supply(db_path=\"random_sample_6.db\",\n",
    "                                          table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    1) Query 'sampled_collections' where marketplace='Atomic',\n",
    "       using 'slug_name' as the collection_name.\n",
    "    2) For each row, call fetch_atomic_collection_stats(...),\n",
    "       parse data[\"data\"][\"assets\"], and store it in 'total_supply'.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_name}\n",
    "    WHERE marketplace='Atomic'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} 'Atomic' collections to update total_supply.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (collection_name,) in rows:\n",
    "        stats_data = fetch_atomic_collection_stats(collection_name)\n",
    "        # stats_data => { \"success\": bool, \"data\": {...}, ... }\n",
    "        if not stats_data.get(\"success\", False):\n",
    "            print(f\"Skipping {collection_name}, 'success' is False or missing.\")\n",
    "            continue\n",
    "        \n",
    "        # If \"assets\" is None or missing, default to \"0\"\n",
    "        assets_str = stats_data.get(\"data\", {}).get(\"assets\")\n",
    "        if assets_str is None:\n",
    "            assets_str = \"0\"\n",
    "        \n",
    "        try:\n",
    "            assets_count = int(assets_str)\n",
    "        except ValueError:\n",
    "            assets_count = 0  # or handle differently if needed\n",
    "        \n",
    "        conn2 = sqlite3.connect(db_path)\n",
    "        c2 = conn2.cursor()\n",
    "        update_stmt = f\"\"\"\n",
    "        UPDATE {table_name}\n",
    "        SET total_supply = ?\n",
    "        WHERE marketplace='Atomic'\n",
    "          AND slug_name=?\n",
    "        \"\"\"\n",
    "        c2.execute(update_stmt, (assets_count, collection_name))\n",
    "        conn2.commit()\n",
    "        conn2.close()\n",
    "        \n",
    "        count += 1\n",
    "        print(f\"[{count}/{len(rows)}] Updated total_supply={assets_count} for {collection_name}\")\n",
    "    \n",
    "    print(\"Done updating total_supply for Atomic collections.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 'Atomic' collections to update total_supply.\n",
      "[1/3] Updated total_supply=22 for oddsandendss\n",
      "[2/3] Updated total_supply=20 for cardinallind\n",
      "[3/3] Updated total_supply=10 for dreamhunters\n",
      "Done updating total_supply for Atomic collections.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    update_atomic_collection_total_supply(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_name=\"sampled_collections\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_atomic_nfts_table(db_path=\"random_sample_6.db\", table_name=\"atomic_nfts\"):\n",
    "    \"\"\"\n",
    "    Creates a table that stores item-level data from the AtomicAssets API.\n",
    "    Adjust columns as needed to match your chosen fields.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    c.execute(f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        \n",
    "        -- references the original 'collection_name' from 'sampled_collections' (Atomic)\n",
    "        collection_name TEXT,\n",
    "        \n",
    "        asset_id TEXT,\n",
    "        owner TEXT,\n",
    "        item_name TEXT,\n",
    "        is_transferable INTEGER,\n",
    "        is_burnable INTEGER,\n",
    "        \n",
    "        template_id TEXT,        -- from template[\"template_id\"]\n",
    "        max_supply TEXT,         -- from template[\"max_supply\"]\n",
    "        issued_supply TEXT,      -- from template[\"issued_supply\"]\n",
    "        \n",
    "        minted_at_time TEXT,     -- item[\"minted_at_time\"]\n",
    "        minted_at_block TEXT,    -- item[\"minted_at_block\"]\n",
    "        \n",
    "        data_json TEXT,          -- optionally store the entire item if you like\n",
    "        fetched_at TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_atomic_assets(collection_name, limit=10):\n",
    "    \"\"\"\n",
    "    Calls the endpoint:\n",
    "      GET /atomicassets/v1/assets?collection_name={collection_name}&limit={limit}\n",
    "    Returns a dict with \"success\", \"data\" (list), and \"query_time\".\n",
    "    We'll return the entire JSON for reference.\n",
    "    \"\"\"\n",
    "    base_url = \"https://wax.api.atomicassets.io/atomicassets/v1/assets\"\n",
    "    params = {\n",
    "        \"collection_name\": collection_name,\n",
    "        \"limit\": limit\n",
    "    }\n",
    "    resp = requests.get(base_url, params=params)\n",
    "    if resp.status_code == 200:\n",
    "        return resp.json()  # e.g. { \"success\": true, \"data\": [...], \"query_time\": 0 }\n",
    "    else:\n",
    "        print(f\"[Atomic NFT Fetch] Error {resp.status_code} => {resp.text}\")\n",
    "        return {}\n",
    "\n",
    "def store_atomic_nfts(db_path, table_name, coll_name, items):\n",
    "    \"\"\"\n",
    "    Inserts the provided item-level data into 'atomic_nfts'.\n",
    "    items is a list of dicts from data[\"data\"] in the AtomicAssets response.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    \n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO {table_name} (\n",
    "        collection_name,\n",
    "        asset_id,\n",
    "        owner,\n",
    "        item_name,\n",
    "        is_transferable,\n",
    "        is_burnable,\n",
    "        template_id,\n",
    "        max_supply,\n",
    "        issued_supply,\n",
    "        minted_at_time,\n",
    "        minted_at_block,\n",
    "        data_json,\n",
    "        fetched_at\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))\n",
    "    \"\"\"\n",
    "    \n",
    "    for item in items:\n",
    "        asset_id = item.get(\"asset_id\", \"\")\n",
    "        owner = item.get(\"owner\", \"\")\n",
    "        item_name = item.get(\"name\", \"\")\n",
    "        \n",
    "        # Convert booleans to int\n",
    "        is_transferable = 1 if item.get(\"is_transferable\", False) else 0\n",
    "        is_burnable = 1 if item.get(\"is_burnable\", False) else 0\n",
    "        \n",
    "        # Safely handle template, which can be None\n",
    "        template = item.get(\"template\") or {}\n",
    "        template_id = template.get(\"template_id\", \"\")\n",
    "        max_supply = template.get(\"max_supply\", \"\")\n",
    "        issued_supply = template.get(\"issued_supply\", \"\")\n",
    "        \n",
    "        minted_at_time = item.get(\"minted_at_time\", \"\")\n",
    "        minted_at_block = item.get(\"minted_at_block\", \"\")\n",
    "        \n",
    "        data_json = json.dumps(item)\n",
    "        \n",
    "        c.execute(insert_sql, (\n",
    "            coll_name,\n",
    "            asset_id,\n",
    "            owner,\n",
    "            item_name,\n",
    "            is_transferable,\n",
    "            is_burnable,\n",
    "            template_id,\n",
    "            max_supply,\n",
    "            issued_supply,\n",
    "            minted_at_time,\n",
    "            minted_at_block,\n",
    "            data_json\n",
    "        ))\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "def fetch_atomic_nfts_for_collections(db_path=\"random_sample_6.db\",\n",
    "                                      table_collections=\"sampled_collections\",\n",
    "                                      table_nfts=\"atomic_nfts\",\n",
    "                                      limit=10):\n",
    "    \"\"\"\n",
    "    1) Create the 'atomic_nfts' table if not exists.\n",
    "    2) Query 'sampled_collections' for marketplace='Atomic'.\n",
    "       We'll assume there's a column 'collection_name' for each row.\n",
    "    3) For each row, call fetch_atomic_assets(collection_name, limit={limit}),\n",
    "       then store them in 'atomic_nfts'.\n",
    "    \"\"\"\n",
    "    # 1) create table\n",
    "    create_atomic_nfts_table(db_path, table_nfts)\n",
    "    \n",
    "    # 2) get the relevant rows from 'sampled_collections'\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    c = conn.cursor()\n",
    "    c.execute(f\"\"\"\n",
    "    SELECT slug_name\n",
    "    FROM {table_collections}\n",
    "    WHERE marketplace='Atomic'\n",
    "      AND slug_name IS NOT NULL\n",
    "    \"\"\")\n",
    "    rows = c.fetchall()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Found {len(rows)} Atomic collections to fetch up to {limit} assets each.\")\n",
    "    \n",
    "    count = 0\n",
    "    for (coll_name,) in rows:\n",
    "        print(f\"[{count+1}/{len(rows)}] Fetching {limit} assets for collection_name='{coll_name}'\")\n",
    "        \n",
    "        data = fetch_atomic_assets(coll_name, limit=limit)\n",
    "        items = data.get(\"data\", [])  # a list of item dicts\n",
    "        \n",
    "        store_atomic_nfts(db_path, table_nfts, coll_name, items)\n",
    "        count += 1\n",
    "    \n",
    "    print(\"Done fetching/storing Atomic NFTs in\", table_nfts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 Atomic collections to fetch up to 10 assets each.\n",
      "[1/3] Fetching 10 assets for collection_name='oddsandendss'\n",
      "[2/3] Fetching 10 assets for collection_name='cardinallind'\n",
      "[3/3] Fetching 10 assets for collection_name='dreamhunters'\n",
      "Done fetching/storing Atomic NFTs in atomic_nfts\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    fetch_atomic_nfts_for_collections(\n",
    "        db_path=\"random_sample_6.db\",\n",
    "        table_collections=\"sampled_collections\",\n",
    "        table_nfts=\"atomic_nfts\",\n",
    "        limit=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
