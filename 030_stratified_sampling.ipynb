{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import sqlite3\n",
    "import random\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import math\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New database for stratified sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_with_same_schema(old_db_path, old_table_name, new_db_path, new_table_name):\n",
    "    \"\"\"\n",
    "    Reads the schema from old_table_name in old_db_path,\n",
    "    and creates an identical table (new_table_name) in new_db_path.\n",
    "    \"\"\"\n",
    "    # Connect to old DB to get schema\n",
    "    old_conn = sqlite3.connect(old_db_path)\n",
    "    old_cursor = old_conn.cursor()\n",
    "    \n",
    "    # We'll read from the SQLite 'PRAGMA table_info(table_name)' command\n",
    "    old_cursor.execute(f\"PRAGMA table_info({old_table_name})\")\n",
    "    schema_info = old_cursor.fetchall()\n",
    "    # schema_info: list of (cid, name, type, notnull, dflt_value, pk)\n",
    "    \n",
    "    column_defs = []\n",
    "    for col in schema_info:\n",
    "        col_name = col[1]\n",
    "        col_type = col[2]  # e.g. TEXT, INTEGER\n",
    "        # We won't replicate 'notnull', 'default_value', etc. for simplicity\n",
    "        column_defs.append(f'\"{col_name}\" {col_type}')\n",
    "    \n",
    "    column_defs_str = \",\\n    \".join(column_defs)\n",
    "    \n",
    "    # Close old DB\n",
    "    old_conn.close()\n",
    "    \n",
    "    # Connect to new DB to create table\n",
    "    new_conn = sqlite3.connect(new_db_path)\n",
    "    new_cursor = new_conn.cursor()\n",
    "    \n",
    "    # Create table statement\n",
    "    create_stmt = f\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS \"{new_table_name}\" (\n",
    "    {column_defs_str}\n",
    "    )\n",
    "    \"\"\"\n",
    "    new_cursor.execute(create_stmt)\n",
    "    new_conn.commit()\n",
    "    new_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling based on marketplace strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_20_collections_per_marketplace(old_db_path=\"data/all_collections.db\",\n",
    "                                          old_table_name=\"data/all_collections\",\n",
    "                                          new_db_path=\"data/stratified_sample.db\",\n",
    "                                          new_table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Reads from old_table_name in old_db_path, samples 20 collections\n",
    "    for each of the four marketplaces, then writes them into\n",
    "    new_db_path:new_table_name.\n",
    "\n",
    "    We'll add four new columns to the new table:\n",
    "      marketplace_stratum, blockchain_stratum, category_stratum, token_standard_stratum\n",
    "\n",
    "    Since we're only sampling by marketplace here,\n",
    "    we'll set marketplace_stratum to mp and the rest to None.\n",
    "    \"\"\"\n",
    "\n",
    "    marketplaces = [\"OpenSea\", \"Rarible\", \"MagicEden\", \"Atomic\"]\n",
    "\n",
    "    # 1) Create the new .db file and a table that mirrors the old table's schema\n",
    "    #    (You must have a function create_table_with_same_schema, not shown here.)\n",
    "    create_table_with_same_schema(old_db_path, old_table_name, new_db_path, new_table_name)\n",
    "\n",
    "    # 2) Connect to both DBs\n",
    "    old_conn = sqlite3.connect(old_db_path)\n",
    "    old_cursor = old_conn.cursor()\n",
    "\n",
    "    new_conn = sqlite3.connect(new_db_path)\n",
    "    new_cursor = new_conn.cursor()\n",
    "\n",
    "    # 3) Add the new \"strata\" columns to the destination table\n",
    "    #    If they already exist, you might catch exceptions or check PRAGMA table_info.\n",
    "    try:\n",
    "        new_cursor.execute(f\"ALTER TABLE {new_table_name} ADD COLUMN marketplace_stratum TEXT\")\n",
    "        new_cursor.execute(f\"ALTER TABLE {new_table_name} ADD COLUMN blockchain_stratum TEXT\")\n",
    "        new_cursor.execute(f\"ALTER TABLE {new_table_name} ADD COLUMN category_stratum TEXT\")\n",
    "        new_cursor.execute(f\"ALTER TABLE {new_table_name} ADD COLUMN token_standard_stratum TEXT\")\n",
    "    except sqlite3.OperationalError as e:\n",
    "        # Columns may already exist, so ignore or handle gracefully\n",
    "        print(\"Warning:\", e)\n",
    "\n",
    "    new_conn.commit()\n",
    "\n",
    "    # Use a fixed seed for reproducibility\n",
    "    random.seed(42)\n",
    "\n",
    "    # Gather column names from the old table\n",
    "    old_cursor.execute(f\"PRAGMA table_info({old_table_name})\")\n",
    "    schema_info = old_cursor.fetchall()\n",
    "    original_col_names = [col[1] for col in schema_info]  # e.g. [\"id\", \"collection_slug\", ...]\n",
    "\n",
    "    # Extend the column list to include the new strata columns\n",
    "    strata_cols = [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]\n",
    "    extended_col_names = original_col_names + strata_cols\n",
    "\n",
    "    # We'll construct an INSERT with placeholders for each column\n",
    "    placeholders = \", \".join(\"?\" for _ in extended_col_names)\n",
    "    col_names_str = \", \".join(f'\"{c}\"' for c in extended_col_names)\n",
    "\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO \"{new_table_name}\" ({col_names_str})\n",
    "    VALUES ({placeholders})\n",
    "    \"\"\"\n",
    "\n",
    "    for mp in marketplaces:\n",
    "        # gather rowid from old table for this marketplace\n",
    "        old_cursor.execute(\n",
    "            f\"SELECT rowid FROM {old_table_name} WHERE marketplace = ?\",\n",
    "            (mp,)\n",
    "        )\n",
    "        rowids = [r[0] for r in old_cursor.fetchall()]\n",
    "        print(f\"{mp} has {len(rowids)} total collections in the DB.\")\n",
    "\n",
    "        # sample 20\n",
    "        desired_count = 20\n",
    "        if len(rowids) < desired_count:\n",
    "            chosen_ids = rowids\n",
    "        else:\n",
    "            chosen_ids = random.sample(rowids, desired_count)\n",
    "\n",
    "        # Build query to fetch full row data\n",
    "        rowid_q = \",\".join(\"?\" * len(chosen_ids))\n",
    "        query = f\"SELECT * FROM {old_table_name} WHERE rowid IN ({rowid_q})\"\n",
    "        old_cursor.execute(query, chosen_ids)\n",
    "        selected_data = old_cursor.fetchall()\n",
    "\n",
    "        # Insert into new DB with extended columns\n",
    "        for row_data in selected_data:\n",
    "            # row_data matches original_col_names in order\n",
    "            # We append the 4 new columns\n",
    "            strata_values = (\n",
    "                mp,       # marketplace_stratum\n",
    "                None,     # blockchain_stratum\n",
    "                None,     # category_stratum\n",
    "                None      # token_standard_stratum\n",
    "            )\n",
    "            extended_row = row_data + strata_values\n",
    "\n",
    "            new_cursor.execute(insert_sql, extended_row)\n",
    "\n",
    "        new_conn.commit()\n",
    "        print(f\"{mp}: Inserted {len(selected_data)} rows into {new_table_name} in {new_db_path}.\")\n",
    "\n",
    "    old_conn.close()\n",
    "    new_conn.close()\n",
    "    print(\"Sampling complete. New data stored in:\", new_db_path, new_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenSea has 1207071 total collections in the DB.\n",
      "OpenSea: Inserted 20 rows into sampled_collections in stratified_sample.db.\n",
      "Rarible has 4201341 total collections in the DB.\n",
      "Rarible: Inserted 20 rows into sampled_collections in stratified_sample.db.\n",
      "MagicEden has 28469 total collections in the DB.\n",
      "MagicEden: Inserted 20 rows into sampled_collections in stratified_sample.db.\n",
      "Atomic has 110142 total collections in the DB.\n",
      "Atomic: Inserted 20 rows into sampled_collections in stratified_sample.db.\n",
      "Sampling complete. New data stored in: stratified_sample.db sampled_collections\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sample_20_collections_per_marketplace(\n",
    "        old_db_path=\"data/all_collections.db\",\n",
    "        old_table_name=\"all_collections\",\n",
    "        new_db_path=\"data/stratified_sample.db\",\n",
    "        new_table_name=\"sampled_collections\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample based on Blockchain strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_2_collections_per_chain(old_db_path=\"data/all_collections.db\",\n",
    "                                   old_table_name=\"all_collections\",\n",
    "                                   new_db_path=\"data/stratified_sample.db\",\n",
    "                                   new_table_name=\"sampled_collections\"):\n",
    "    \"\"\"\n",
    "    Reads from old_table_name in old_db_path, samples 2 collections per distinct chain\n",
    "    (derived by splitting the 'collection_id' field on ':' -> chain).\n",
    "    Writes them into new_db_path:new_table_name with the same schema + new strata columns.\n",
    "    \"\"\"\n",
    "    # 1) Create new DB & table\n",
    "    create_table_with_same_schema(old_db_path, old_table_name, new_db_path, new_table_name)\n",
    "\n",
    "    old_conn = sqlite3.connect(old_db_path)\n",
    "    old_cursor = old_conn.cursor()\n",
    "\n",
    "    new_conn = sqlite3.connect(new_db_path)\n",
    "    new_cursor = new_conn.cursor()\n",
    "\n",
    "    # 2) Add the new strata columns if not exist\n",
    "    for col in [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]:\n",
    "        try:\n",
    "            new_cursor.execute(f\"ALTER TABLE {new_table_name} ADD COLUMN {col} TEXT\")\n",
    "        except sqlite3.OperationalError:\n",
    "            pass\n",
    "\n",
    "    new_conn.commit()\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    # Build insert statement\n",
    "    old_cursor.execute(f\"PRAGMA table_info({old_table_name})\")\n",
    "    schema_info = old_cursor.fetchall()\n",
    "    original_col_names = [col[1] for col in schema_info]\n",
    "\n",
    "    strata_cols = [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]\n",
    "    extended_col_names = original_col_names + strata_cols\n",
    "\n",
    "    placeholders = \", \".join(\"?\" for _ in extended_col_names)\n",
    "    col_names_str = \", \".join(f'\"{c}\"' for c in extended_col_names)\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO \"{new_table_name}\" ({col_names_str})\n",
    "    VALUES ({placeholders})\n",
    "    \"\"\"\n",
    "\n",
    "    # 3) chain -> list of rowids\n",
    "    chain_dict = {}\n",
    "    old_cursor.execute(f\"SELECT rowid, collection_id FROM {old_table_name}\")\n",
    "    all_rows = old_cursor.fetchall()\n",
    "\n",
    "    for rowid, coll_id in all_rows:\n",
    "        if not coll_id or \":\" not in coll_id:\n",
    "            continue\n",
    "        _id, chain = coll_id.split(\":\", 1)\n",
    "        chain = chain.strip().lower()\n",
    "        if not chain:\n",
    "            continue\n",
    "        chain_dict.setdefault(chain, []).append(rowid)\n",
    "\n",
    "    for chain, rowids in chain_dict.items():\n",
    "        desired_count = 2\n",
    "        chosen_ids = random.sample(rowids, desired_count) if len(rowids) > desired_count else rowids\n",
    "\n",
    "        if chosen_ids:\n",
    "            rowid_q = \",\".join(\"?\" * len(chosen_ids))\n",
    "            query = f\"SELECT * FROM {old_table_name} WHERE rowid IN ({rowid_q})\"\n",
    "            old_cursor.execute(query, chosen_ids)\n",
    "            selected_data = old_cursor.fetchall()\n",
    "\n",
    "            for row_data in selected_data:\n",
    "                # Append strata\n",
    "                strata_values = (\n",
    "                    None,  # marketplace_stratum\n",
    "                    chain, # blockchain_stratum\n",
    "                    None,  # category_stratum\n",
    "                    None   # token_standard_stratum\n",
    "                )\n",
    "                extended_row = row_data + strata_values\n",
    "                new_cursor.execute(insert_sql, extended_row)\n",
    "            new_conn.commit()\n",
    "\n",
    "    old_conn.close()\n",
    "    new_conn.close()\n",
    "    print(\"Sampling by chain complete. Data stored in:\", new_db_path, new_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling by chain complete. Data stored in: stratified_sample.db sampled_collections\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sample_2_collections_per_chain(\n",
    "        old_db_path=\"data/all_collections.db\",\n",
    "        old_table_name=\"all_collections\",\n",
    "        new_db_path=\"data/stratified_sample.db\",\n",
    "        new_table_name=\"sampled_collections\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample based on Category strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_collections_per_category(old_db_path=\"data/all_collections.db\",\n",
    "                                    old_table_name=\"all_collections\",\n",
    "                                    new_db_path=\"data/stratified_sample.db\",\n",
    "                                    new_table_name=\"sampled_collections\",\n",
    "                                    samples_per_category=5):\n",
    "    \"\"\"\n",
    "    Reads from old_table_name in old_db_path, samples N collections per distinct category,\n",
    "    writes them into new_db_path:new_table_name with the same schema + new strata columns.\n",
    "    \"\"\"\n",
    "    # 1) Create new DB & table\n",
    "    create_table_with_same_schema(old_db_path, old_table_name, new_db_path, new_table_name)\n",
    "\n",
    "    old_conn = sqlite3.connect(old_db_path)\n",
    "    old_cursor = old_conn.cursor()\n",
    "\n",
    "    new_conn = sqlite3.connect(new_db_path)\n",
    "    new_cursor = new_conn.cursor()\n",
    "\n",
    "    random.seed(42)\n",
    "\n",
    "    # 2) Add new strata columns\n",
    "    for col in [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]:\n",
    "        try:\n",
    "            new_cursor.execute(f\"ALTER TABLE {new_table_name} ADD COLUMN {col} TEXT\")\n",
    "        except sqlite3.OperationalError:\n",
    "            pass\n",
    "\n",
    "    new_conn.commit()\n",
    "\n",
    "    # Build insert statement\n",
    "    old_cursor.execute(f\"PRAGMA table_info({old_table_name})\")\n",
    "    schema_info = old_cursor.fetchall()\n",
    "    original_col_names = [col[1] for col in schema_info]\n",
    "\n",
    "    strata_cols = [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]\n",
    "    extended_col_names = original_col_names + strata_cols\n",
    "\n",
    "    placeholders = \", \".join(\"?\" for _ in extended_col_names)\n",
    "    col_names_str = \", \".join(f'\"{c}\"' for c in extended_col_names)\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO \"{new_table_name}\" ({col_names_str})\n",
    "    VALUES ({placeholders})\n",
    "    \"\"\"\n",
    "\n",
    "    # 3) category -> rowids\n",
    "    category_dict = {}\n",
    "    old_cursor.execute(f\"SELECT rowid, category FROM {old_table_name}\")\n",
    "    all_rows = old_cursor.fetchall()\n",
    "\n",
    "    for rowid, cat_val in all_rows:\n",
    "        if not cat_val or not cat_val.strip():\n",
    "            continue\n",
    "\n",
    "        cat_val = cat_val.strip()\n",
    "        categories = []\n",
    "\n",
    "        try:\n",
    "            # If it's JSON-like, parse it\n",
    "            if cat_val.startswith(\"[\") and cat_val.endswith(\"]\"):\n",
    "                parsed = json.loads(cat_val)\n",
    "                categories = [c for c in parsed if c]\n",
    "            else:\n",
    "                categories = [cat_val]\n",
    "        except Exception:\n",
    "            categories = [cat_val]\n",
    "\n",
    "        for cat in categories:\n",
    "            cat = cat.strip().lower()\n",
    "            if cat:\n",
    "                category_dict.setdefault(cat, []).append(rowid)\n",
    "\n",
    "    unique_categories = list(category_dict.keys())\n",
    "    print(f\"Total distinct categories found: {len(unique_categories)}\")\n",
    "\n",
    "    for cat, rowids in category_dict.items():\n",
    "        if len(rowids) <= samples_per_category:\n",
    "            chosen_ids = rowids\n",
    "        else:\n",
    "            chosen_ids = random.sample(rowids, samples_per_category)\n",
    "\n",
    "        if chosen_ids:\n",
    "            rowid_q = \",\".join(\"?\" * len(chosen_ids))\n",
    "            query = f\"SELECT * FROM {old_table_name} WHERE rowid IN ({rowid_q})\"\n",
    "            old_cursor.execute(query, chosen_ids)\n",
    "            selected_data = old_cursor.fetchall()\n",
    "\n",
    "            for row_data in selected_data:\n",
    "                strata_values = (\n",
    "                    None,    # marketplace_stratum\n",
    "                    None,    # blockchain_stratum\n",
    "                    cat,     # category_stratum\n",
    "                    None     # token_standard_stratum\n",
    "                )\n",
    "                extended_row = row_data + strata_values\n",
    "                new_cursor.execute(insert_sql, extended_row)\n",
    "            new_conn.commit()\n",
    "\n",
    "    old_conn.close()\n",
    "    new_conn.close()\n",
    "    print(\"Sampling by category complete. Data stored in:\", new_db_path, new_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct categories found: 15\n",
      "Sampling by category complete. Data stored in: stratified_sample.db sampled_collections\n"
     ]
    }
   ],
   "source": [
    "sample_collections_per_category(samples_per_category=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample based on Token Standard Strata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique_token_standards(db_path=\"data/all_collections.db\", table_name=\"all_collections\"):\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    cursor.execute(f\"SELECT token_standard FROM {table_name}\")\n",
    "    all_token_standards = cursor.fetchall()\n",
    "    \n",
    "    counter = Counter()\n",
    "    \n",
    "    for (cat_val,) in all_token_standards:\n",
    "        if cat_val is None or cat_val.strip() == \"\":\n",
    "            continue\n",
    "        cat_val = cat_val.strip()\n",
    "        counter[cat_val] += 1\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"Total unique token_standards found: {len(counter)}\")\n",
    "    print(\"Token Standards (with counts):\")\n",
    "    for standard, count in sorted(counter.items()):\n",
    "        print(f\"{standard}: {count}\")\n",
    "    \n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique token_standards found: 6\n",
      "Token Standards (with counts):\n",
      "APTOS: 168782\n",
      "CRYPTO_PUNKS: 1\n",
      "ERC1155: 927807\n",
      "ERC721: 3104663\n",
      "FLOW: 18\n",
      "TOKEN_GROUP_2022: 70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'ERC721': 3104663,\n",
       "         'ERC1155': 927807,\n",
       "         'TOKEN_GROUP_2022': 70,\n",
       "         'APTOS': 168782,\n",
       "         'FLOW': 18,\n",
       "         'CRYPTO_PUNKS': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_unique_token_standards()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_collections_per_token_standard(existing_db_path=\"data/stratified_sample.db\",\n",
    "                                          existing_table_name=\"sampled_collections\",\n",
    "                                          source_db_path=\"data/all_collections.db\",\n",
    "                                          source_table_name=\"all_collections\",\n",
    "                                          samples_per_standard=10,\n",
    "                                          seed=42):\n",
    "    \"\"\"\n",
    "    Samples N collections per unique token_standard from the source database and appends\n",
    "    them into an existing target table in an existing target database, adding the\n",
    "    four strata columns if needed.\n",
    "    \"\"\"\n",
    "    source_conn = sqlite3.connect(source_db_path)\n",
    "    source_cursor = source_conn.cursor()\n",
    "\n",
    "    target_conn = sqlite3.connect(existing_db_path)\n",
    "    target_cursor = target_conn.cursor()\n",
    "\n",
    "    random.seed(seed)\n",
    "\n",
    "    # 1) Add new strata columns if not exist\n",
    "    for col in [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]:\n",
    "        try:\n",
    "            target_cursor.execute(f\"ALTER TABLE {existing_table_name} ADD COLUMN {col} TEXT\")\n",
    "        except sqlite3.OperationalError:\n",
    "            pass\n",
    "\n",
    "    target_conn.commit()\n",
    "\n",
    "    # 2) Build insert statement based on source table columns\n",
    "    source_cursor.execute(f\"PRAGMA table_info({source_table_name})\")\n",
    "    schema_info = source_cursor.fetchall()\n",
    "    original_col_names = [col[1] for col in schema_info]\n",
    "\n",
    "    strata_cols = [\"marketplace_stratum\", \"blockchain_stratum\", \"category_stratum\", \"token_standard_stratum\"]\n",
    "    extended_col_names = original_col_names + strata_cols\n",
    "\n",
    "    placeholders = \", \".join(\"?\" for _ in extended_col_names)\n",
    "    col_names_str = \", \".join(f'\"{c}\"' for c in extended_col_names)\n",
    "    insert_sql = f\"\"\"\n",
    "    INSERT INTO \"{existing_table_name}\" ({col_names_str})\n",
    "    VALUES ({placeholders})\n",
    "    \"\"\"\n",
    "\n",
    "    # 3) token_standard -> list of rowids\n",
    "    token_dict = {}\n",
    "    source_cursor.execute(f\"SELECT rowid, token_standard FROM {source_table_name}\")\n",
    "    all_rows = source_cursor.fetchall()\n",
    "\n",
    "    for rowid, token_val in all_rows:\n",
    "        if not token_val or not token_val.strip():\n",
    "            continue\n",
    "        token = token_val.strip().lower()\n",
    "        token_dict.setdefault(token, []).append(rowid)\n",
    "\n",
    "    print(f\"Total distinct token standards found: {len(token_dict)}\")\n",
    "\n",
    "    # 4) Sample per token standard\n",
    "    for token, rowids in token_dict.items():\n",
    "        if len(rowids) <= samples_per_standard:\n",
    "            chosen_ids = rowids\n",
    "        else:\n",
    "            chosen_ids = random.sample(rowids, samples_per_standard)\n",
    "\n",
    "        if chosen_ids:\n",
    "            rowid_q = \",\".join(\"?\" * len(chosen_ids))\n",
    "            query = f\"SELECT * FROM {source_table_name} WHERE rowid IN ({rowid_q})\"\n",
    "            source_cursor.execute(query, chosen_ids)\n",
    "            selected_data = source_cursor.fetchall()\n",
    "\n",
    "            for row_data in selected_data:\n",
    "                strata_values = (\n",
    "                    None,     # marketplace_stratum\n",
    "                    None,     # blockchain_stratum\n",
    "                    None,     # category_stratum\n",
    "                    token     # token_standard_stratum\n",
    "                )\n",
    "                extended_row = row_data + strata_values\n",
    "                target_cursor.execute(insert_sql, extended_row)\n",
    "            target_conn.commit()\n",
    "\n",
    "    source_conn.close()\n",
    "    target_conn.close()\n",
    "    print(\"Sampling by token standard complete. Data appended to:\", existing_db_path, existing_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total distinct token standards found: 6\n",
      "Sampling by token standard complete. Data appended to: stratified_sample.db sampled_collections\n"
     ]
    }
   ],
   "source": [
    "sample_collections_per_token_standard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
